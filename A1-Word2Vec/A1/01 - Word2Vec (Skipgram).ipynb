{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec (Skipgram )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib\n",
    "import time\n",
    "import nltk.corpus \n",
    "from nltk.corpus import brown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.3.5', '2.5.1+cu121', '3.10.8')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__, torch.__version__, matplotlib.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load brown corpus (real-world data for final training)\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "sentences = brown.sents(categories = \"news\")\n",
    "sentences = [[word.lower() for word in sent] for sent in sentences]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We use the brown news dataset provided by the NLTK library.  \n",
    "This dataset contains news articles across multiple topics and is commonly used for NLP research.\n",
    "Using this dataset allows us to train word embeddings on real-world text instead of toy examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokenized sentences: 4623\n",
      "Sample tokenized sentence (first 30 words):\n",
      "['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', \"atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Tokenize brown corpus\n",
    "\n",
    "tokenized_sentences = sentences\n",
    "\n",
    "print(\"Number of tokenized sentences:\", len(tokenized_sentences))\n",
    "print(\"Sample tokenized sentence (first 30 words):\")\n",
    "print(tokenized_sentences[0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of (center, context) pairs generated: 374548\n",
      "Sample (center, context) pairs: [('the', 'fulton'), ('the', 'county'), ('fulton', 'the'), ('fulton', 'county'), ('fulton', 'grand'), ('county', 'the'), ('county', 'fulton'), ('county', 'grand'), ('county', 'jury'), ('grand', 'fulton')]\n"
     ]
    }
   ],
   "source": [
    "def generate_context(sentence, center_idx, window_size=2):\n",
    "    \"\"\"\n",
    "    Generate context words for a given center word index using a dynamic window size.\n",
    "    \"\"\"\n",
    "    start = max(0, center_idx - window_size)\n",
    "    end = min(len(sentence), center_idx + window_size + 1)\n",
    "    return [sentence[j] for j in range(start, end) if j != center_idx]\n",
    "\n",
    "\n",
    "def generate_skipgram_pairs(sentences, window_size=2):\n",
    "    \"\"\"\n",
    "    Generate (center, context) pairs for Skip-gram training.\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    for sentence in sentences:\n",
    "        for i, center in enumerate(sentence):\n",
    "            context_words = generate_context(sentence, i, window_size)\n",
    "            for context in context_words:\n",
    "                pairs.append((center, context))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "# Default window size\n",
    "window_size = 2\n",
    "\n",
    "# Generate Skip-gram training pairs\n",
    "pairs = generate_skipgram_pairs(tokenized_sentences, window_size)\n",
    "print(\"Number of (center, context) pairs generated:\", len(pairs))\n",
    "print(\"Sample (center, context) pairs:\", pairs[:10])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(batch_size, sentences, word2index, window_size=2):\n",
    "    \"\"\"\n",
    "    Generate a random batch of (center, context) word index pairs\n",
    "    using a dynamic window size.\n",
    "    \"\"\"\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    while len(inputs) < batch_size:\n",
    "        # Randomly choose a sentence\n",
    "        sentence = sentences[np.random.randint(len(sentences))]\n",
    "        \n",
    "        # Randomly choose a center word index\n",
    "        center_idx = np.random.randint(len(sentence))\n",
    "        center_word = sentence[center_idx]\n",
    "        center = word2index.get(center_word, word2index[\"<UNK>\"])\n",
    "\n",
    "        # Generate context words dynamically\n",
    "        context_words = generate_context(sentence, center_idx, window_size)\n",
    "\n",
    "        for context_word in context_words:\n",
    "            if len(inputs) >= batch_size:\n",
    "                break\n",
    "            context = word2index.get(context_word, word2index[\"<UNK>\"])\n",
    "            inputs.append(center)\n",
    "            labels.append(context)\n",
    "\n",
    "    return np.array(inputs), np.array(labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{T}\\sum_{t=1}^{T}\\sum_{\\substack{-m \\leq j \\leq m \\\\ j \\neq 0}}\\log P(w_{t+j} | w_t; \\theta)$$\n",
    "\n",
    "where $P(w_{t+j} | w_t; \\theta) = $\n",
    "\n",
    "$$P(o|c)=\\frac{\\exp(\\mathbf{u_o^{\\top}v_c})}{\\sum_{w=1}^V\\exp(\\mathbf{u_w^{\\top}v_c})}$$\n",
    "\n",
    "where $o$ is the outside words and $c$ is the center word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(o|c)=\\frac{\\exp(\\mathbf{u_o^{\\top}v_c})}{\\sum_{w=1}^V\\exp(\\mathbf{u_w^{\\top}v_c})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super().__init__()\n",
    "        self.embedding_center = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
    "\n",
    "    def forward(self, center, outside, all_vocabs):\n",
    "        \"\"\"\n",
    "        center: (batch_size, 1)\n",
    "        outside: (batch_size, 1)\n",
    "        all_vocabs: (batch_size, voc_size)\n",
    "        \"\"\"\n",
    "        v_c = self.embedding_center(center)          # (B, 1, D)\n",
    "        u_o = self.embedding_outside(outside)        # (B, 1, D)\n",
    "        u_all = self.embedding_outside(all_vocabs)   # (B, V, D)\n",
    "\n",
    "        # Positive score\n",
    "        score = torch.bmm(u_o, v_c.transpose(1, 2)).squeeze(2)\n",
    "\n",
    "        # All vocabulary scores\n",
    "        all_scores = torch.bmm(u_all, v_c.transpose(1, 2)).squeeze(2)\n",
    "\n",
    "        log_probs = torch.log_softmax(all_scores, dim=1)\n",
    "\n",
    "        loss = -torch.mean(log_probs.gather(1, outside))\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set()\n",
    "for doc in tokenized_sentences:\n",
    "    unique_words.update(doc)\n",
    "\n",
    "vocabs = list(unique_words)\n",
    "vocabs.append(\"<UNK>\")\n",
    "\n",
    "word2index = {word: idx for idx, word in enumerate(vocabs)}\n",
    "tokenized_corpus = tokenized_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = len(vocabs)\n",
    "emb_size = 16   # recommended: 50 (fast) or 100 (better)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_vocabs(vocabs, word2index, batch_size):\n",
    "    \"\"\"\n",
    "    Prepare a tensor containing all vocabulary indices,\n",
    "    expanded for batch-wise full softmax computation.\n",
    "    \"\"\"\n",
    "    idxs = [word2index.get(w, word2index[\"<UNK>\"]) for w in vocabs]\n",
    "    all_vocab_tensor = torch.LongTensor(idxs).unsqueeze(0)\n",
    "    return all_vocab_tensor.expand(batch_size, len(vocabs))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Skipgram(voc_size, emb_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "num_epochs = 1000\n",
    "batch_size = 12\n",
    "window_size = 2  # DEFAULT (assignment requirement)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] - Loss: 17.0462\n",
      "Epoch [2/1000] - Loss: 16.5478\n",
      "Epoch [3/1000] - Loss: 16.4906\n",
      "Epoch [4/1000] - Loss: 16.1668\n",
      "Epoch [5/1000] - Loss: 15.9137\n",
      "Epoch [6/1000] - Loss: 15.7166\n",
      "Epoch [7/1000] - Loss: 15.6223\n",
      "Epoch [8/1000] - Loss: 15.2167\n",
      "Epoch [9/1000] - Loss: 15.2023\n",
      "Epoch [10/1000] - Loss: 15.0184\n",
      "Epoch [11/1000] - Loss: 14.8468\n",
      "Epoch [12/1000] - Loss: 14.9968\n",
      "Epoch [13/1000] - Loss: 14.6697\n",
      "Epoch [14/1000] - Loss: 14.4808\n",
      "Epoch [15/1000] - Loss: 14.3400\n",
      "Epoch [16/1000] - Loss: 14.4113\n",
      "Epoch [17/1000] - Loss: 13.9322\n",
      "Epoch [18/1000] - Loss: 14.1240\n",
      "Epoch [19/1000] - Loss: 13.9001\n",
      "Epoch [20/1000] - Loss: 14.2575\n",
      "Epoch [21/1000] - Loss: 13.6119\n",
      "Epoch [22/1000] - Loss: 13.7951\n",
      "Epoch [23/1000] - Loss: 13.7358\n",
      "Epoch [24/1000] - Loss: 13.4233\n",
      "Epoch [25/1000] - Loss: 13.4328\n",
      "Epoch [26/1000] - Loss: 13.2488\n",
      "Epoch [27/1000] - Loss: 13.5283\n",
      "Epoch [28/1000] - Loss: 13.0982\n",
      "Epoch [29/1000] - Loss: 13.5042\n",
      "Epoch [30/1000] - Loss: 12.9921\n",
      "Epoch [31/1000] - Loss: 13.3222\n",
      "Epoch [32/1000] - Loss: 13.1086\n",
      "Epoch [33/1000] - Loss: 12.9861\n",
      "Epoch [34/1000] - Loss: 13.0115\n",
      "Epoch [35/1000] - Loss: 12.7160\n",
      "Epoch [36/1000] - Loss: 12.9316\n",
      "Epoch [37/1000] - Loss: 12.7499\n",
      "Epoch [38/1000] - Loss: 12.6212\n",
      "Epoch [39/1000] - Loss: 12.6174\n",
      "Epoch [40/1000] - Loss: 12.7990\n",
      "Epoch [41/1000] - Loss: 12.3781\n",
      "Epoch [42/1000] - Loss: 12.5515\n",
      "Epoch [43/1000] - Loss: 12.3212\n",
      "Epoch [44/1000] - Loss: 12.4463\n",
      "Epoch [45/1000] - Loss: 11.8510\n",
      "Epoch [46/1000] - Loss: 12.1449\n",
      "Epoch [47/1000] - Loss: 12.2462\n",
      "Epoch [48/1000] - Loss: 12.0715\n",
      "Epoch [49/1000] - Loss: 12.0007\n",
      "Epoch [50/1000] - Loss: 11.9976\n",
      "Epoch [51/1000] - Loss: 12.0697\n",
      "Epoch [52/1000] - Loss: 11.5497\n",
      "Epoch [53/1000] - Loss: 11.9501\n",
      "Epoch [54/1000] - Loss: 11.9014\n",
      "Epoch [55/1000] - Loss: 11.8676\n",
      "Epoch [56/1000] - Loss: 11.7567\n",
      "Epoch [57/1000] - Loss: 11.9772\n",
      "Epoch [58/1000] - Loss: 11.4743\n",
      "Epoch [59/1000] - Loss: 11.8344\n",
      "Epoch [60/1000] - Loss: 11.6516\n",
      "Epoch [61/1000] - Loss: 11.6432\n",
      "Epoch [62/1000] - Loss: 11.6564\n",
      "Epoch [63/1000] - Loss: 11.4893\n",
      "Epoch [64/1000] - Loss: 11.5853\n",
      "Epoch [65/1000] - Loss: 11.4213\n",
      "Epoch [66/1000] - Loss: 11.3544\n",
      "Epoch [67/1000] - Loss: 11.3096\n",
      "Epoch [68/1000] - Loss: 11.3612\n",
      "Epoch [69/1000] - Loss: 11.3360\n",
      "Epoch [70/1000] - Loss: 11.3540\n",
      "Epoch [71/1000] - Loss: 10.9672\n",
      "Epoch [72/1000] - Loss: 11.1788\n",
      "Epoch [73/1000] - Loss: 11.1929\n",
      "Epoch [74/1000] - Loss: 11.1469\n",
      "Epoch [75/1000] - Loss: 11.0850\n",
      "Epoch [76/1000] - Loss: 11.0427\n",
      "Epoch [77/1000] - Loss: 10.7975\n",
      "Epoch [78/1000] - Loss: 11.1444\n",
      "Epoch [79/1000] - Loss: 11.0042\n",
      "Epoch [80/1000] - Loss: 11.0979\n",
      "Epoch [81/1000] - Loss: 10.9714\n",
      "Epoch [82/1000] - Loss: 10.9246\n",
      "Epoch [83/1000] - Loss: 10.7194\n",
      "Epoch [84/1000] - Loss: 10.5902\n",
      "Epoch [85/1000] - Loss: 10.6999\n",
      "Epoch [86/1000] - Loss: 11.0056\n",
      "Epoch [87/1000] - Loss: 10.7855\n",
      "Epoch [88/1000] - Loss: 10.8819\n",
      "Epoch [89/1000] - Loss: 10.6180\n",
      "Epoch [90/1000] - Loss: 10.5173\n",
      "Epoch [91/1000] - Loss: 10.6662\n",
      "Epoch [92/1000] - Loss: 10.6132\n",
      "Epoch [93/1000] - Loss: 10.5636\n",
      "Epoch [94/1000] - Loss: 10.5852\n",
      "Epoch [95/1000] - Loss: 10.3768\n",
      "Epoch [96/1000] - Loss: 10.1972\n",
      "Epoch [97/1000] - Loss: 10.1594\n",
      "Epoch [98/1000] - Loss: 10.3414\n",
      "Epoch [99/1000] - Loss: 10.3417\n",
      "Epoch [100/1000] - Loss: 10.1611\n",
      "Epoch [101/1000] - Loss: 10.3195\n",
      "Epoch [102/1000] - Loss: 10.4420\n",
      "Epoch [103/1000] - Loss: 10.3595\n",
      "Epoch [104/1000] - Loss: 10.2248\n",
      "Epoch [105/1000] - Loss: 10.2981\n",
      "Epoch [106/1000] - Loss: 10.2022\n",
      "Epoch [107/1000] - Loss: 9.9203\n",
      "Epoch [108/1000] - Loss: 10.2193\n",
      "Epoch [109/1000] - Loss: 10.0653\n",
      "Epoch [110/1000] - Loss: 9.9995\n",
      "Epoch [111/1000] - Loss: 9.8413\n",
      "Epoch [112/1000] - Loss: 9.9896\n",
      "Epoch [113/1000] - Loss: 10.0842\n",
      "Epoch [114/1000] - Loss: 10.0211\n",
      "Epoch [115/1000] - Loss: 9.9478\n",
      "Epoch [116/1000] - Loss: 9.8588\n",
      "Epoch [117/1000] - Loss: 9.7420\n",
      "Epoch [118/1000] - Loss: 9.9664\n",
      "Epoch [119/1000] - Loss: 9.8021\n",
      "Epoch [120/1000] - Loss: 9.7437\n",
      "Epoch [121/1000] - Loss: 9.6494\n",
      "Epoch [122/1000] - Loss: 9.7129\n",
      "Epoch [123/1000] - Loss: 9.6546\n",
      "Epoch [124/1000] - Loss: 9.8333\n",
      "Epoch [125/1000] - Loss: 9.6810\n",
      "Epoch [126/1000] - Loss: 9.6749\n",
      "Epoch [127/1000] - Loss: 9.6502\n",
      "Epoch [128/1000] - Loss: 9.6720\n",
      "Epoch [129/1000] - Loss: 9.6690\n",
      "Epoch [130/1000] - Loss: 9.5706\n",
      "Epoch [131/1000] - Loss: 9.5492\n",
      "Epoch [132/1000] - Loss: 9.6342\n",
      "Epoch [133/1000] - Loss: 9.4185\n",
      "Epoch [134/1000] - Loss: 9.6377\n",
      "Epoch [135/1000] - Loss: 9.6481\n",
      "Epoch [136/1000] - Loss: 9.5819\n",
      "Epoch [137/1000] - Loss: 9.4922\n",
      "Epoch [138/1000] - Loss: 9.6731\n",
      "Epoch [139/1000] - Loss: 9.4400\n",
      "Epoch [140/1000] - Loss: 9.1912\n",
      "Epoch [141/1000] - Loss: 9.4245\n",
      "Epoch [142/1000] - Loss: 9.4428\n",
      "Epoch [143/1000] - Loss: 9.4509\n",
      "Epoch [144/1000] - Loss: 9.3472\n",
      "Epoch [145/1000] - Loss: 9.2364\n",
      "Epoch [146/1000] - Loss: 9.3078\n",
      "Epoch [147/1000] - Loss: 9.2373\n",
      "Epoch [148/1000] - Loss: 9.2100\n",
      "Epoch [149/1000] - Loss: 9.2375\n",
      "Epoch [150/1000] - Loss: 9.2055\n",
      "Epoch [151/1000] - Loss: 9.2527\n",
      "Epoch [152/1000] - Loss: 9.3146\n",
      "Epoch [153/1000] - Loss: 9.3633\n",
      "Epoch [154/1000] - Loss: 9.0011\n",
      "Epoch [155/1000] - Loss: 9.0872\n",
      "Epoch [156/1000] - Loss: 9.0696\n",
      "Epoch [157/1000] - Loss: 9.2979\n",
      "Epoch [158/1000] - Loss: 9.1835\n",
      "Epoch [159/1000] - Loss: 9.2461\n",
      "Epoch [160/1000] - Loss: 9.2325\n",
      "Epoch [161/1000] - Loss: 8.8981\n",
      "Epoch [162/1000] - Loss: 9.0925\n",
      "Epoch [163/1000] - Loss: 9.1043\n",
      "Epoch [164/1000] - Loss: 9.3258\n",
      "Epoch [165/1000] - Loss: 9.1271\n",
      "Epoch [166/1000] - Loss: 8.9487\n",
      "Epoch [167/1000] - Loss: 8.9627\n",
      "Epoch [168/1000] - Loss: 8.9640\n",
      "Epoch [169/1000] - Loss: 8.9516\n",
      "Epoch [170/1000] - Loss: 8.8766\n",
      "Epoch [171/1000] - Loss: 9.0079\n",
      "Epoch [172/1000] - Loss: 8.8522\n",
      "Epoch [173/1000] - Loss: 8.8339\n",
      "Epoch [174/1000] - Loss: 8.8959\n",
      "Epoch [175/1000] - Loss: 8.5822\n",
      "Epoch [176/1000] - Loss: 8.7616\n",
      "Epoch [177/1000] - Loss: 8.7721\n",
      "Epoch [178/1000] - Loss: 8.8827\n",
      "Epoch [179/1000] - Loss: 8.7952\n",
      "Epoch [180/1000] - Loss: 8.8648\n",
      "Epoch [181/1000] - Loss: 8.8491\n",
      "Epoch [182/1000] - Loss: 8.7879\n",
      "Epoch [183/1000] - Loss: 8.7206\n",
      "Epoch [184/1000] - Loss: 8.7200\n",
      "Epoch [185/1000] - Loss: 8.9561\n",
      "Epoch [186/1000] - Loss: 8.6635\n",
      "Epoch [187/1000] - Loss: 8.9331\n",
      "Epoch [188/1000] - Loss: 8.5893\n",
      "Epoch [189/1000] - Loss: 8.9788\n",
      "Epoch [190/1000] - Loss: 8.6574\n",
      "Epoch [191/1000] - Loss: 8.5989\n",
      "Epoch [192/1000] - Loss: 8.8942\n",
      "Epoch [193/1000] - Loss: 8.5719\n",
      "Epoch [194/1000] - Loss: 8.5489\n",
      "Epoch [195/1000] - Loss: 8.6117\n",
      "Epoch [196/1000] - Loss: 8.9068\n",
      "Epoch [197/1000] - Loss: 8.5356\n",
      "Epoch [198/1000] - Loss: 8.6390\n",
      "Epoch [199/1000] - Loss: 8.5485\n",
      "Epoch [200/1000] - Loss: 8.3734\n",
      "Epoch [201/1000] - Loss: 8.5957\n",
      "Epoch [202/1000] - Loss: 8.5968\n",
      "Epoch [203/1000] - Loss: 8.4231\n",
      "Epoch [204/1000] - Loss: 8.4103\n",
      "Epoch [205/1000] - Loss: 8.6431\n",
      "Epoch [206/1000] - Loss: 8.4615\n",
      "Epoch [207/1000] - Loss: 8.5849\n",
      "Epoch [208/1000] - Loss: 8.6635\n",
      "Epoch [209/1000] - Loss: 8.5266\n",
      "Epoch [210/1000] - Loss: 8.5119\n",
      "Epoch [211/1000] - Loss: 8.6172\n",
      "Epoch [212/1000] - Loss: 8.3838\n",
      "Epoch [213/1000] - Loss: 8.5536\n",
      "Epoch [214/1000] - Loss: 8.4980\n",
      "Epoch [215/1000] - Loss: 8.5947\n",
      "Epoch [216/1000] - Loss: 8.5058\n",
      "Epoch [217/1000] - Loss: 8.6251\n",
      "Epoch [218/1000] - Loss: 8.2478\n",
      "Epoch [219/1000] - Loss: 8.4101\n",
      "Epoch [220/1000] - Loss: 8.2825\n",
      "Epoch [221/1000] - Loss: 8.6142\n",
      "Epoch [222/1000] - Loss: 8.5525\n",
      "Epoch [223/1000] - Loss: 8.4323\n",
      "Epoch [224/1000] - Loss: 8.3347\n",
      "Epoch [225/1000] - Loss: 8.5682\n",
      "Epoch [226/1000] - Loss: 8.6441\n",
      "Epoch [227/1000] - Loss: 8.3152\n",
      "Epoch [228/1000] - Loss: 8.4612\n",
      "Epoch [229/1000] - Loss: 8.0736\n",
      "Epoch [230/1000] - Loss: 8.4860\n",
      "Epoch [231/1000] - Loss: 8.4397\n",
      "Epoch [232/1000] - Loss: 8.5148\n",
      "Epoch [233/1000] - Loss: 8.2369\n",
      "Epoch [234/1000] - Loss: 8.3638\n",
      "Epoch [235/1000] - Loss: 8.3280\n",
      "Epoch [236/1000] - Loss: 8.3874\n",
      "Epoch [237/1000] - Loss: 8.2919\n",
      "Epoch [238/1000] - Loss: 8.1657\n",
      "Epoch [239/1000] - Loss: 8.2692\n",
      "Epoch [240/1000] - Loss: 8.4544\n",
      "Epoch [241/1000] - Loss: 8.2277\n",
      "Epoch [242/1000] - Loss: 8.1898\n",
      "Epoch [243/1000] - Loss: 8.2477\n",
      "Epoch [244/1000] - Loss: 8.1743\n",
      "Epoch [245/1000] - Loss: 8.2676\n",
      "Epoch [246/1000] - Loss: 8.1992\n",
      "Epoch [247/1000] - Loss: 8.1392\n",
      "Epoch [248/1000] - Loss: 8.2651\n",
      "Epoch [249/1000] - Loss: 8.0670\n",
      "Epoch [250/1000] - Loss: 8.1830\n",
      "Epoch [251/1000] - Loss: 8.3260\n",
      "Epoch [252/1000] - Loss: 8.3605\n",
      "Epoch [253/1000] - Loss: 8.1753\n",
      "Epoch [254/1000] - Loss: 8.2355\n",
      "Epoch [255/1000] - Loss: 8.2638\n",
      "Epoch [256/1000] - Loss: 8.2372\n",
      "Epoch [257/1000] - Loss: 8.2528\n",
      "Epoch [258/1000] - Loss: 8.2408\n",
      "Epoch [259/1000] - Loss: 8.1900\n",
      "Epoch [260/1000] - Loss: 8.0221\n",
      "Epoch [261/1000] - Loss: 8.2522\n",
      "Epoch [262/1000] - Loss: 8.1624\n",
      "Epoch [263/1000] - Loss: 8.2417\n",
      "Epoch [264/1000] - Loss: 8.3044\n",
      "Epoch [265/1000] - Loss: 8.0231\n",
      "Epoch [266/1000] - Loss: 8.1564\n",
      "Epoch [267/1000] - Loss: 8.0359\n",
      "Epoch [268/1000] - Loss: 8.1367\n",
      "Epoch [269/1000] - Loss: 8.2067\n",
      "Epoch [270/1000] - Loss: 8.1626\n",
      "Epoch [271/1000] - Loss: 8.1686\n",
      "Epoch [272/1000] - Loss: 8.2322\n",
      "Epoch [273/1000] - Loss: 8.0621\n",
      "Epoch [274/1000] - Loss: 8.1906\n",
      "Epoch [275/1000] - Loss: 8.0513\n",
      "Epoch [276/1000] - Loss: 7.9242\n",
      "Epoch [277/1000] - Loss: 8.1241\n",
      "Epoch [278/1000] - Loss: 8.3416\n",
      "Epoch [279/1000] - Loss: 7.7753\n",
      "Epoch [280/1000] - Loss: 8.2086\n",
      "Epoch [281/1000] - Loss: 8.1725\n",
      "Epoch [282/1000] - Loss: 8.1618\n",
      "Epoch [283/1000] - Loss: 8.0248\n",
      "Epoch [284/1000] - Loss: 8.0808\n",
      "Epoch [285/1000] - Loss: 8.0042\n",
      "Epoch [286/1000] - Loss: 8.1965\n",
      "Epoch [287/1000] - Loss: 8.0347\n",
      "Epoch [288/1000] - Loss: 7.8866\n",
      "Epoch [289/1000] - Loss: 8.1185\n",
      "Epoch [290/1000] - Loss: 8.1291\n",
      "Epoch [291/1000] - Loss: 8.0720\n",
      "Epoch [292/1000] - Loss: 8.0899\n",
      "Epoch [293/1000] - Loss: 8.0897\n",
      "Epoch [294/1000] - Loss: 7.9797\n",
      "Epoch [295/1000] - Loss: 7.8789\n",
      "Epoch [296/1000] - Loss: 7.8090\n",
      "Epoch [297/1000] - Loss: 8.5410\n",
      "Epoch [298/1000] - Loss: 8.0604\n",
      "Epoch [299/1000] - Loss: 7.8383\n",
      "Epoch [300/1000] - Loss: 7.9806\n",
      "Epoch [301/1000] - Loss: 8.0861\n",
      "Epoch [302/1000] - Loss: 8.0230\n",
      "Epoch [303/1000] - Loss: 7.9421\n",
      "Epoch [304/1000] - Loss: 7.9323\n",
      "Epoch [305/1000] - Loss: 8.0078\n",
      "Epoch [306/1000] - Loss: 8.1332\n",
      "Epoch [307/1000] - Loss: 7.9995\n",
      "Epoch [308/1000] - Loss: 7.8975\n",
      "Epoch [309/1000] - Loss: 8.1264\n",
      "Epoch [310/1000] - Loss: 7.9579\n",
      "Epoch [311/1000] - Loss: 7.7827\n",
      "Epoch [312/1000] - Loss: 7.7796\n",
      "Epoch [313/1000] - Loss: 7.8210\n",
      "Epoch [314/1000] - Loss: 8.0425\n",
      "Epoch [315/1000] - Loss: 7.9365\n",
      "Epoch [316/1000] - Loss: 7.9960\n",
      "Epoch [317/1000] - Loss: 7.8834\n",
      "Epoch [318/1000] - Loss: 7.8698\n",
      "Epoch [319/1000] - Loss: 7.9233\n",
      "Epoch [320/1000] - Loss: 7.8869\n",
      "Epoch [321/1000] - Loss: 7.7716\n",
      "Epoch [322/1000] - Loss: 7.7978\n",
      "Epoch [323/1000] - Loss: 7.8644\n",
      "Epoch [324/1000] - Loss: 7.9427\n",
      "Epoch [325/1000] - Loss: 7.8229\n",
      "Epoch [326/1000] - Loss: 7.8752\n",
      "Epoch [327/1000] - Loss: 8.1333\n",
      "Epoch [328/1000] - Loss: 7.8118\n",
      "Epoch [329/1000] - Loss: 7.8708\n",
      "Epoch [330/1000] - Loss: 7.9785\n",
      "Epoch [331/1000] - Loss: 7.7701\n",
      "Epoch [332/1000] - Loss: 7.9676\n",
      "Epoch [333/1000] - Loss: 7.8310\n",
      "Epoch [334/1000] - Loss: 7.9228\n",
      "Epoch [335/1000] - Loss: 7.8346\n",
      "Epoch [336/1000] - Loss: 7.7128\n",
      "Epoch [337/1000] - Loss: 8.0293\n",
      "Epoch [338/1000] - Loss: 7.7861\n",
      "Epoch [339/1000] - Loss: 8.0184\n",
      "Epoch [340/1000] - Loss: 7.8282\n",
      "Epoch [341/1000] - Loss: 7.6093\n",
      "Epoch [342/1000] - Loss: 7.6284\n",
      "Epoch [343/1000] - Loss: 7.7316\n",
      "Epoch [344/1000] - Loss: 7.8902\n",
      "Epoch [345/1000] - Loss: 7.7411\n",
      "Epoch [346/1000] - Loss: 7.7865\n",
      "Epoch [347/1000] - Loss: 7.7948\n",
      "Epoch [348/1000] - Loss: 7.6606\n",
      "Epoch [349/1000] - Loss: 7.8774\n",
      "Epoch [350/1000] - Loss: 7.8980\n",
      "Epoch [351/1000] - Loss: 7.7540\n",
      "Epoch [352/1000] - Loss: 7.7253\n",
      "Epoch [353/1000] - Loss: 7.7089\n",
      "Epoch [354/1000] - Loss: 7.7954\n",
      "Epoch [355/1000] - Loss: 7.9109\n",
      "Epoch [356/1000] - Loss: 7.9682\n",
      "Epoch [357/1000] - Loss: 7.9720\n",
      "Epoch [358/1000] - Loss: 7.7050\n",
      "Epoch [359/1000] - Loss: 7.8972\n",
      "Epoch [360/1000] - Loss: 7.7743\n",
      "Epoch [361/1000] - Loss: 7.8393\n",
      "Epoch [362/1000] - Loss: 7.8639\n",
      "Epoch [363/1000] - Loss: 7.6142\n",
      "Epoch [364/1000] - Loss: 7.6753\n",
      "Epoch [365/1000] - Loss: 7.7760\n",
      "Epoch [366/1000] - Loss: 7.7018\n",
      "Epoch [367/1000] - Loss: 7.7335\n",
      "Epoch [368/1000] - Loss: 7.7750\n",
      "Epoch [369/1000] - Loss: 7.7122\n",
      "Epoch [370/1000] - Loss: 7.6972\n",
      "Epoch [371/1000] - Loss: 7.7067\n",
      "Epoch [372/1000] - Loss: 7.8696\n",
      "Epoch [373/1000] - Loss: 7.7381\n",
      "Epoch [374/1000] - Loss: 7.7527\n",
      "Epoch [375/1000] - Loss: 7.8330\n",
      "Epoch [376/1000] - Loss: 7.6670\n",
      "Epoch [377/1000] - Loss: 7.6776\n",
      "Epoch [378/1000] - Loss: 7.6278\n",
      "Epoch [379/1000] - Loss: 7.7955\n",
      "Epoch [380/1000] - Loss: 7.8930\n",
      "Epoch [381/1000] - Loss: 7.6936\n",
      "Epoch [382/1000] - Loss: 7.7349\n",
      "Epoch [383/1000] - Loss: 7.6402\n",
      "Epoch [384/1000] - Loss: 7.6294\n",
      "Epoch [385/1000] - Loss: 7.6601\n",
      "Epoch [386/1000] - Loss: 7.6085\n",
      "Epoch [387/1000] - Loss: 7.6344\n",
      "Epoch [388/1000] - Loss: 7.6791\n",
      "Epoch [389/1000] - Loss: 7.6583\n",
      "Epoch [390/1000] - Loss: 8.0139\n",
      "Epoch [391/1000] - Loss: 7.6058\n",
      "Epoch [392/1000] - Loss: 7.7849\n",
      "Epoch [393/1000] - Loss: 7.5022\n",
      "Epoch [394/1000] - Loss: 7.7171\n",
      "Epoch [395/1000] - Loss: 7.8664\n",
      "Epoch [396/1000] - Loss: 7.7456\n",
      "Epoch [397/1000] - Loss: 7.5742\n",
      "Epoch [398/1000] - Loss: 7.5020\n",
      "Epoch [399/1000] - Loss: 7.7966\n",
      "Epoch [400/1000] - Loss: 7.5609\n",
      "Epoch [401/1000] - Loss: 7.5436\n",
      "Epoch [402/1000] - Loss: 7.4814\n",
      "Epoch [403/1000] - Loss: 7.4307\n",
      "Epoch [404/1000] - Loss: 7.7327\n",
      "Epoch [405/1000] - Loss: 7.6151\n",
      "Epoch [406/1000] - Loss: 7.5224\n",
      "Epoch [407/1000] - Loss: 7.6895\n",
      "Epoch [408/1000] - Loss: 7.6512\n",
      "Epoch [409/1000] - Loss: 7.6199\n",
      "Epoch [410/1000] - Loss: 7.6168\n",
      "Epoch [411/1000] - Loss: 7.5152\n",
      "Epoch [412/1000] - Loss: 7.8055\n",
      "Epoch [413/1000] - Loss: 7.5640\n",
      "Epoch [414/1000] - Loss: 7.5406\n",
      "Epoch [415/1000] - Loss: 7.5592\n",
      "Epoch [416/1000] - Loss: 7.6804\n",
      "Epoch [417/1000] - Loss: 7.5886\n",
      "Epoch [418/1000] - Loss: 7.4496\n",
      "Epoch [419/1000] - Loss: 7.7491\n",
      "Epoch [420/1000] - Loss: 7.5835\n",
      "Epoch [421/1000] - Loss: 7.6478\n",
      "Epoch [422/1000] - Loss: 7.5861\n",
      "Epoch [423/1000] - Loss: 7.5308\n",
      "Epoch [424/1000] - Loss: 7.4735\n",
      "Epoch [425/1000] - Loss: 7.8166\n",
      "Epoch [426/1000] - Loss: 7.6277\n",
      "Epoch [427/1000] - Loss: 7.7404\n",
      "Epoch [428/1000] - Loss: 7.7913\n",
      "Epoch [429/1000] - Loss: 7.7006\n",
      "Epoch [430/1000] - Loss: 7.5321\n",
      "Epoch [431/1000] - Loss: 7.5793\n",
      "Epoch [432/1000] - Loss: 7.4219\n",
      "Epoch [433/1000] - Loss: 7.6319\n",
      "Epoch [434/1000] - Loss: 7.6380\n",
      "Epoch [435/1000] - Loss: 7.7094\n",
      "Epoch [436/1000] - Loss: 7.7063\n",
      "Epoch [437/1000] - Loss: 7.5620\n",
      "Epoch [438/1000] - Loss: 7.4975\n",
      "Epoch [439/1000] - Loss: 7.4797\n",
      "Epoch [440/1000] - Loss: 7.5149\n",
      "Epoch [441/1000] - Loss: 7.4855\n",
      "Epoch [442/1000] - Loss: 7.5798\n",
      "Epoch [443/1000] - Loss: 7.4982\n",
      "Epoch [444/1000] - Loss: 7.6251\n",
      "Epoch [445/1000] - Loss: 7.6063\n",
      "Epoch [446/1000] - Loss: 7.5520\n",
      "Epoch [447/1000] - Loss: 7.6586\n",
      "Epoch [448/1000] - Loss: 7.5605\n",
      "Epoch [449/1000] - Loss: 7.5221\n",
      "Epoch [450/1000] - Loss: 7.4760\n",
      "Epoch [451/1000] - Loss: 7.5682\n",
      "Epoch [452/1000] - Loss: 7.7343\n",
      "Epoch [453/1000] - Loss: 7.6060\n",
      "Epoch [454/1000] - Loss: 7.6978\n",
      "Epoch [455/1000] - Loss: 7.6548\n",
      "Epoch [456/1000] - Loss: 7.5490\n",
      "Epoch [457/1000] - Loss: 7.4677\n",
      "Epoch [458/1000] - Loss: 7.5215\n",
      "Epoch [459/1000] - Loss: 7.5038\n",
      "Epoch [460/1000] - Loss: 7.4943\n",
      "Epoch [461/1000] - Loss: 7.5222\n",
      "Epoch [462/1000] - Loss: 7.4956\n",
      "Epoch [463/1000] - Loss: 7.4013\n",
      "Epoch [464/1000] - Loss: 7.4660\n",
      "Epoch [465/1000] - Loss: 7.5138\n",
      "Epoch [466/1000] - Loss: 7.2705\n",
      "Epoch [467/1000] - Loss: 7.7497\n",
      "Epoch [468/1000] - Loss: 7.4063\n",
      "Epoch [469/1000] - Loss: 7.4693\n",
      "Epoch [470/1000] - Loss: 7.5856\n",
      "Epoch [471/1000] - Loss: 7.5344\n",
      "Epoch [472/1000] - Loss: 7.6778\n",
      "Epoch [473/1000] - Loss: 7.6647\n",
      "Epoch [474/1000] - Loss: 7.4604\n",
      "Epoch [475/1000] - Loss: 7.5432\n",
      "Epoch [476/1000] - Loss: 7.3953\n",
      "Epoch [477/1000] - Loss: 7.6075\n",
      "Epoch [478/1000] - Loss: 7.7077\n",
      "Epoch [479/1000] - Loss: 7.4577\n",
      "Epoch [480/1000] - Loss: 7.4826\n",
      "Epoch [481/1000] - Loss: 7.5188\n",
      "Epoch [482/1000] - Loss: 7.4743\n",
      "Epoch [483/1000] - Loss: 7.4582\n",
      "Epoch [484/1000] - Loss: 7.4743\n",
      "Epoch [485/1000] - Loss: 7.4879\n",
      "Epoch [486/1000] - Loss: 7.5294\n",
      "Epoch [487/1000] - Loss: 7.5509\n",
      "Epoch [488/1000] - Loss: 7.3900\n",
      "Epoch [489/1000] - Loss: 7.4471\n",
      "Epoch [490/1000] - Loss: 7.4446\n",
      "Epoch [491/1000] - Loss: 7.6091\n",
      "Epoch [492/1000] - Loss: 7.4005\n",
      "Epoch [493/1000] - Loss: 7.4557\n",
      "Epoch [494/1000] - Loss: 7.5357\n",
      "Epoch [495/1000] - Loss: 7.6245\n",
      "Epoch [496/1000] - Loss: 7.4551\n",
      "Epoch [497/1000] - Loss: 7.3356\n",
      "Epoch [498/1000] - Loss: 7.4192\n",
      "Epoch [499/1000] - Loss: 7.5763\n",
      "Epoch [500/1000] - Loss: 7.3653\n",
      "Epoch [501/1000] - Loss: 7.4396\n",
      "Epoch [502/1000] - Loss: 7.4618\n",
      "Epoch [503/1000] - Loss: 7.3589\n",
      "Epoch [504/1000] - Loss: 7.6200\n",
      "Epoch [505/1000] - Loss: 7.4465\n",
      "Epoch [506/1000] - Loss: 7.4893\n",
      "Epoch [507/1000] - Loss: 7.4805\n",
      "Epoch [508/1000] - Loss: 7.5439\n",
      "Epoch [509/1000] - Loss: 7.2851\n",
      "Epoch [510/1000] - Loss: 7.3272\n",
      "Epoch [511/1000] - Loss: 7.3722\n",
      "Epoch [512/1000] - Loss: 7.4994\n",
      "Epoch [513/1000] - Loss: 7.5019\n",
      "Epoch [514/1000] - Loss: 7.4080\n",
      "Epoch [515/1000] - Loss: 7.3102\n",
      "Epoch [516/1000] - Loss: 7.3183\n",
      "Epoch [517/1000] - Loss: 7.5399\n",
      "Epoch [518/1000] - Loss: 7.5972\n",
      "Epoch [519/1000] - Loss: 7.5869\n",
      "Epoch [520/1000] - Loss: 7.5445\n",
      "Epoch [521/1000] - Loss: 7.2138\n",
      "Epoch [522/1000] - Loss: 7.3724\n",
      "Epoch [523/1000] - Loss: 7.4103\n",
      "Epoch [524/1000] - Loss: 7.3042\n",
      "Epoch [525/1000] - Loss: 7.4485\n",
      "Epoch [526/1000] - Loss: 7.4936\n",
      "Epoch [527/1000] - Loss: 7.4293\n",
      "Epoch [528/1000] - Loss: 7.5042\n",
      "Epoch [529/1000] - Loss: 7.1095\n",
      "Epoch [530/1000] - Loss: 7.2623\n",
      "Epoch [531/1000] - Loss: 7.4868\n",
      "Epoch [532/1000] - Loss: 7.4259\n",
      "Epoch [533/1000] - Loss: 7.4366\n",
      "Epoch [534/1000] - Loss: 7.1313\n",
      "Epoch [535/1000] - Loss: 7.4254\n",
      "Epoch [536/1000] - Loss: 7.3580\n",
      "Epoch [537/1000] - Loss: 7.4344\n",
      "Epoch [538/1000] - Loss: 7.2468\n",
      "Epoch [539/1000] - Loss: 7.6598\n",
      "Epoch [540/1000] - Loss: 7.6060\n",
      "Epoch [541/1000] - Loss: 7.5695\n",
      "Epoch [542/1000] - Loss: 7.5243\n",
      "Epoch [543/1000] - Loss: 7.3555\n",
      "Epoch [544/1000] - Loss: 7.3469\n",
      "Epoch [545/1000] - Loss: 7.3435\n",
      "Epoch [546/1000] - Loss: 7.3950\n",
      "Epoch [547/1000] - Loss: 7.5654\n",
      "Epoch [548/1000] - Loss: 7.4260\n",
      "Epoch [549/1000] - Loss: 7.4981\n",
      "Epoch [550/1000] - Loss: 7.3013\n",
      "Epoch [551/1000] - Loss: 7.5742\n",
      "Epoch [552/1000] - Loss: 7.3403\n",
      "Epoch [553/1000] - Loss: 7.4303\n",
      "Epoch [554/1000] - Loss: 7.6492\n",
      "Epoch [555/1000] - Loss: 7.4628\n",
      "Epoch [556/1000] - Loss: 7.3890\n",
      "Epoch [557/1000] - Loss: 7.2941\n",
      "Epoch [558/1000] - Loss: 7.4241\n",
      "Epoch [559/1000] - Loss: 7.3518\n",
      "Epoch [560/1000] - Loss: 7.3819\n",
      "Epoch [561/1000] - Loss: 7.3570\n",
      "Epoch [562/1000] - Loss: 7.4318\n",
      "Epoch [563/1000] - Loss: 7.3343\n",
      "Epoch [564/1000] - Loss: 7.4710\n",
      "Epoch [565/1000] - Loss: 7.4592\n",
      "Epoch [566/1000] - Loss: 7.4077\n",
      "Epoch [567/1000] - Loss: 7.3381\n",
      "Epoch [568/1000] - Loss: 7.4955\n",
      "Epoch [569/1000] - Loss: 7.3348\n",
      "Epoch [570/1000] - Loss: 7.5852\n",
      "Epoch [571/1000] - Loss: 7.3462\n",
      "Epoch [572/1000] - Loss: 7.3676\n",
      "Epoch [573/1000] - Loss: 7.4074\n",
      "Epoch [574/1000] - Loss: 7.4571\n",
      "Epoch [575/1000] - Loss: 7.3009\n",
      "Epoch [576/1000] - Loss: 7.3925\n",
      "Epoch [577/1000] - Loss: 7.3655\n",
      "Epoch [578/1000] - Loss: 7.3095\n",
      "Epoch [579/1000] - Loss: 7.2643\n",
      "Epoch [580/1000] - Loss: 7.1348\n",
      "Epoch [581/1000] - Loss: 7.3113\n",
      "Epoch [582/1000] - Loss: 7.2485\n",
      "Epoch [583/1000] - Loss: 7.4279\n",
      "Epoch [584/1000] - Loss: 7.3020\n",
      "Epoch [585/1000] - Loss: 7.4023\n",
      "Epoch [586/1000] - Loss: 7.4364\n",
      "Epoch [587/1000] - Loss: 7.3205\n",
      "Epoch [588/1000] - Loss: 7.2460\n",
      "Epoch [589/1000] - Loss: 7.2832\n",
      "Epoch [590/1000] - Loss: 7.4285\n",
      "Epoch [591/1000] - Loss: 7.3312\n",
      "Epoch [592/1000] - Loss: 7.3848\n",
      "Epoch [593/1000] - Loss: 7.3603\n",
      "Epoch [594/1000] - Loss: 7.3186\n",
      "Epoch [595/1000] - Loss: 7.3940\n",
      "Epoch [596/1000] - Loss: 7.4102\n",
      "Epoch [597/1000] - Loss: 7.4473\n",
      "Epoch [598/1000] - Loss: 7.3928\n",
      "Epoch [599/1000] - Loss: 7.2286\n",
      "Epoch [600/1000] - Loss: 7.4357\n",
      "Epoch [601/1000] - Loss: 7.3125\n",
      "Epoch [602/1000] - Loss: 7.3005\n",
      "Epoch [603/1000] - Loss: 7.3713\n",
      "Epoch [604/1000] - Loss: 7.3154\n",
      "Epoch [605/1000] - Loss: 7.1604\n",
      "Epoch [606/1000] - Loss: 7.4407\n",
      "Epoch [607/1000] - Loss: 7.2827\n",
      "Epoch [608/1000] - Loss: 7.3554\n",
      "Epoch [609/1000] - Loss: 7.3570\n",
      "Epoch [610/1000] - Loss: 7.5591\n",
      "Epoch [611/1000] - Loss: 7.3237\n",
      "Epoch [612/1000] - Loss: 7.3358\n",
      "Epoch [613/1000] - Loss: 7.2198\n",
      "Epoch [614/1000] - Loss: 7.3615\n",
      "Epoch [615/1000] - Loss: 7.1783\n",
      "Epoch [616/1000] - Loss: 7.1327\n",
      "Epoch [617/1000] - Loss: 7.4097\n",
      "Epoch [618/1000] - Loss: 7.3165\n",
      "Epoch [619/1000] - Loss: 7.4737\n",
      "Epoch [620/1000] - Loss: 7.2540\n",
      "Epoch [621/1000] - Loss: 7.2952\n",
      "Epoch [622/1000] - Loss: 7.2734\n",
      "Epoch [623/1000] - Loss: 7.2642\n",
      "Epoch [624/1000] - Loss: 7.4041\n",
      "Epoch [625/1000] - Loss: 7.1003\n",
      "Epoch [626/1000] - Loss: 7.3348\n",
      "Epoch [627/1000] - Loss: 7.3579\n",
      "Epoch [628/1000] - Loss: 7.2219\n",
      "Epoch [629/1000] - Loss: 7.2865\n",
      "Epoch [630/1000] - Loss: 7.2373\n",
      "Epoch [631/1000] - Loss: 7.2184\n",
      "Epoch [632/1000] - Loss: 7.2899\n",
      "Epoch [633/1000] - Loss: 7.4400\n",
      "Epoch [634/1000] - Loss: 7.3621\n",
      "Epoch [635/1000] - Loss: 7.3546\n",
      "Epoch [636/1000] - Loss: 7.4860\n",
      "Epoch [637/1000] - Loss: 7.4255\n",
      "Epoch [638/1000] - Loss: 7.3635\n",
      "Epoch [639/1000] - Loss: 7.1883\n",
      "Epoch [640/1000] - Loss: 7.2547\n",
      "Epoch [641/1000] - Loss: 7.5122\n",
      "Epoch [642/1000] - Loss: 7.4303\n",
      "Epoch [643/1000] - Loss: 7.1034\n",
      "Epoch [644/1000] - Loss: 7.3717\n",
      "Epoch [645/1000] - Loss: 7.5085\n",
      "Epoch [646/1000] - Loss: 7.1735\n",
      "Epoch [647/1000] - Loss: 7.3739\n",
      "Epoch [648/1000] - Loss: 7.4923\n",
      "Epoch [649/1000] - Loss: 7.3249\n",
      "Epoch [650/1000] - Loss: 7.2278\n",
      "Epoch [651/1000] - Loss: 7.2211\n",
      "Epoch [652/1000] - Loss: 7.3172\n",
      "Epoch [653/1000] - Loss: 7.2909\n",
      "Epoch [654/1000] - Loss: 7.2437\n",
      "Epoch [655/1000] - Loss: 7.3875\n",
      "Epoch [656/1000] - Loss: 7.2212\n",
      "Epoch [657/1000] - Loss: 7.5401\n",
      "Epoch [658/1000] - Loss: 7.2010\n",
      "Epoch [659/1000] - Loss: 7.3242\n",
      "Epoch [660/1000] - Loss: 7.2401\n",
      "Epoch [661/1000] - Loss: 7.3721\n",
      "Epoch [662/1000] - Loss: 7.2462\n",
      "Epoch [663/1000] - Loss: 7.2390\n",
      "Epoch [664/1000] - Loss: 7.4377\n",
      "Epoch [665/1000] - Loss: 7.2177\n",
      "Epoch [666/1000] - Loss: 7.2655\n",
      "Epoch [667/1000] - Loss: 7.2868\n",
      "Epoch [668/1000] - Loss: 7.2873\n",
      "Epoch [669/1000] - Loss: 7.3180\n",
      "Epoch [670/1000] - Loss: 7.3834\n",
      "Epoch [671/1000] - Loss: 7.2502\n",
      "Epoch [672/1000] - Loss: 7.2448\n",
      "Epoch [673/1000] - Loss: 7.1876\n",
      "Epoch [674/1000] - Loss: 7.4015\n",
      "Epoch [675/1000] - Loss: 7.2366\n",
      "Epoch [676/1000] - Loss: 7.3135\n",
      "Epoch [677/1000] - Loss: 7.4474\n",
      "Epoch [678/1000] - Loss: 7.1648\n",
      "Epoch [679/1000] - Loss: 7.3295\n",
      "Epoch [680/1000] - Loss: 7.3885\n",
      "Epoch [681/1000] - Loss: 7.1344\n",
      "Epoch [682/1000] - Loss: 7.3716\n",
      "Epoch [683/1000] - Loss: 7.3888\n",
      "Epoch [684/1000] - Loss: 7.2656\n",
      "Epoch [685/1000] - Loss: 7.2851\n",
      "Epoch [686/1000] - Loss: 7.2615\n",
      "Epoch [687/1000] - Loss: 7.0943\n",
      "Epoch [688/1000] - Loss: 7.1074\n",
      "Epoch [689/1000] - Loss: 7.3333\n",
      "Epoch [690/1000] - Loss: 7.2713\n",
      "Epoch [691/1000] - Loss: 7.3481\n",
      "Epoch [692/1000] - Loss: 7.1971\n",
      "Epoch [693/1000] - Loss: 7.3297\n",
      "Epoch [694/1000] - Loss: 7.2951\n",
      "Epoch [695/1000] - Loss: 7.5973\n",
      "Epoch [696/1000] - Loss: 7.4138\n",
      "Epoch [697/1000] - Loss: 7.1158\n",
      "Epoch [698/1000] - Loss: 7.2248\n",
      "Epoch [699/1000] - Loss: 7.2789\n",
      "Epoch [700/1000] - Loss: 7.3442\n",
      "Epoch [701/1000] - Loss: 7.2586\n",
      "Epoch [702/1000] - Loss: 7.3269\n",
      "Epoch [703/1000] - Loss: 7.4009\n",
      "Epoch [704/1000] - Loss: 7.1731\n",
      "Epoch [705/1000] - Loss: 7.3565\n",
      "Epoch [706/1000] - Loss: 7.2800\n",
      "Epoch [707/1000] - Loss: 7.1264\n",
      "Epoch [708/1000] - Loss: 7.2600\n",
      "Epoch [709/1000] - Loss: 7.2587\n",
      "Epoch [710/1000] - Loss: 7.1816\n",
      "Epoch [711/1000] - Loss: 7.3865\n",
      "Epoch [712/1000] - Loss: 7.2934\n",
      "Epoch [713/1000] - Loss: 7.1078\n",
      "Epoch [714/1000] - Loss: 7.4907\n",
      "Epoch [715/1000] - Loss: 7.2930\n",
      "Epoch [716/1000] - Loss: 7.4671\n",
      "Epoch [717/1000] - Loss: 7.2131\n",
      "Epoch [718/1000] - Loss: 7.1088\n",
      "Epoch [719/1000] - Loss: 6.9629\n",
      "Epoch [720/1000] - Loss: 7.0563\n",
      "Epoch [721/1000] - Loss: 7.2787\n",
      "Epoch [722/1000] - Loss: 7.2965\n",
      "Epoch [723/1000] - Loss: 7.2075\n",
      "Epoch [724/1000] - Loss: 7.3851\n",
      "Epoch [725/1000] - Loss: 7.0556\n",
      "Epoch [726/1000] - Loss: 7.0280\n",
      "Epoch [727/1000] - Loss: 7.1500\n",
      "Epoch [728/1000] - Loss: 7.4552\n",
      "Epoch [729/1000] - Loss: 7.3611\n",
      "Epoch [730/1000] - Loss: 7.2849\n",
      "Epoch [731/1000] - Loss: 7.4058\n",
      "Epoch [732/1000] - Loss: 7.1845\n",
      "Epoch [733/1000] - Loss: 7.1468\n",
      "Epoch [734/1000] - Loss: 7.1839\n",
      "Epoch [735/1000] - Loss: 7.0876\n",
      "Epoch [736/1000] - Loss: 7.2279\n",
      "Epoch [737/1000] - Loss: 7.4731\n",
      "Epoch [738/1000] - Loss: 7.2728\n",
      "Epoch [739/1000] - Loss: 7.3951\n",
      "Epoch [740/1000] - Loss: 7.1990\n",
      "Epoch [741/1000] - Loss: 7.3220\n",
      "Epoch [742/1000] - Loss: 7.0136\n",
      "Epoch [743/1000] - Loss: 7.2118\n",
      "Epoch [744/1000] - Loss: 7.1604\n",
      "Epoch [745/1000] - Loss: 7.5157\n",
      "Epoch [746/1000] - Loss: 7.1518\n",
      "Epoch [747/1000] - Loss: 7.1728\n",
      "Epoch [748/1000] - Loss: 7.4326\n",
      "Epoch [749/1000] - Loss: 7.1341\n",
      "Epoch [750/1000] - Loss: 7.3165\n",
      "Epoch [751/1000] - Loss: 7.2128\n",
      "Epoch [752/1000] - Loss: 7.1464\n",
      "Epoch [753/1000] - Loss: 7.2821\n",
      "Epoch [754/1000] - Loss: 7.3236\n",
      "Epoch [755/1000] - Loss: 7.1119\n",
      "Epoch [756/1000] - Loss: 7.1274\n",
      "Epoch [757/1000] - Loss: 7.2342\n",
      "Epoch [758/1000] - Loss: 7.1290\n",
      "Epoch [759/1000] - Loss: 7.1782\n",
      "Epoch [760/1000] - Loss: 7.2095\n",
      "Epoch [761/1000] - Loss: 7.3109\n",
      "Epoch [762/1000] - Loss: 7.2437\n",
      "Epoch [763/1000] - Loss: 7.2295\n",
      "Epoch [764/1000] - Loss: 7.1176\n",
      "Epoch [765/1000] - Loss: 7.2011\n",
      "Epoch [766/1000] - Loss: 7.2620\n",
      "Epoch [767/1000] - Loss: 7.2742\n",
      "Epoch [768/1000] - Loss: 7.3142\n",
      "Epoch [769/1000] - Loss: 7.1062\n",
      "Epoch [770/1000] - Loss: 7.2969\n",
      "Epoch [771/1000] - Loss: 7.2887\n",
      "Epoch [772/1000] - Loss: 7.0794\n",
      "Epoch [773/1000] - Loss: 7.4147\n",
      "Epoch [774/1000] - Loss: 7.4954\n",
      "Epoch [775/1000] - Loss: 7.2922\n",
      "Epoch [776/1000] - Loss: 7.1460\n",
      "Epoch [777/1000] - Loss: 7.1902\n",
      "Epoch [778/1000] - Loss: 7.0881\n",
      "Epoch [779/1000] - Loss: 7.1412\n",
      "Epoch [780/1000] - Loss: 7.2335\n",
      "Epoch [781/1000] - Loss: 7.1669\n",
      "Epoch [782/1000] - Loss: 7.3172\n",
      "Epoch [783/1000] - Loss: 7.1702\n",
      "Epoch [784/1000] - Loss: 7.4553\n",
      "Epoch [785/1000] - Loss: 7.1157\n",
      "Epoch [786/1000] - Loss: 7.2122\n",
      "Epoch [787/1000] - Loss: 7.2210\n",
      "Epoch [788/1000] - Loss: 7.0687\n",
      "Epoch [789/1000] - Loss: 7.0721\n",
      "Epoch [790/1000] - Loss: 7.1525\n",
      "Epoch [791/1000] - Loss: 7.1587\n",
      "Epoch [792/1000] - Loss: 7.2968\n",
      "Epoch [793/1000] - Loss: 7.3860\n",
      "Epoch [794/1000] - Loss: 7.1340\n",
      "Epoch [795/1000] - Loss: 7.1785\n",
      "Epoch [796/1000] - Loss: 7.4336\n",
      "Epoch [797/1000] - Loss: 6.9537\n",
      "Epoch [798/1000] - Loss: 7.2093\n",
      "Epoch [799/1000] - Loss: 7.1511\n",
      "Epoch [800/1000] - Loss: 7.4520\n",
      "Epoch [801/1000] - Loss: 7.1259\n",
      "Epoch [802/1000] - Loss: 7.1586\n",
      "Epoch [803/1000] - Loss: 7.2184\n",
      "Epoch [804/1000] - Loss: 7.1334\n",
      "Epoch [805/1000] - Loss: 7.3321\n",
      "Epoch [806/1000] - Loss: 7.4252\n",
      "Epoch [807/1000] - Loss: 7.1163\n",
      "Epoch [808/1000] - Loss: 7.1477\n",
      "Epoch [809/1000] - Loss: 7.2773\n",
      "Epoch [810/1000] - Loss: 7.2698\n",
      "Epoch [811/1000] - Loss: 7.1234\n",
      "Epoch [812/1000] - Loss: 7.2514\n",
      "Epoch [813/1000] - Loss: 7.3413\n",
      "Epoch [814/1000] - Loss: 7.2853\n",
      "Epoch [815/1000] - Loss: 7.0225\n",
      "Epoch [816/1000] - Loss: 7.1045\n",
      "Epoch [817/1000] - Loss: 7.1225\n",
      "Epoch [818/1000] - Loss: 7.3937\n",
      "Epoch [819/1000] - Loss: 7.1895\n",
      "Epoch [820/1000] - Loss: 7.0319\n",
      "Epoch [821/1000] - Loss: 7.3461\n",
      "Epoch [822/1000] - Loss: 7.2304\n",
      "Epoch [823/1000] - Loss: 7.3027\n",
      "Epoch [824/1000] - Loss: 7.1235\n",
      "Epoch [825/1000] - Loss: 7.1990\n",
      "Epoch [826/1000] - Loss: 7.1014\n",
      "Epoch [827/1000] - Loss: 7.1313\n",
      "Epoch [828/1000] - Loss: 7.4495\n",
      "Epoch [829/1000] - Loss: 7.1279\n",
      "Epoch [830/1000] - Loss: 7.3473\n",
      "Epoch [831/1000] - Loss: 7.2147\n",
      "Epoch [832/1000] - Loss: 7.2097\n",
      "Epoch [833/1000] - Loss: 7.1210\n",
      "Epoch [834/1000] - Loss: 7.1951\n",
      "Epoch [835/1000] - Loss: 7.2206\n",
      "Epoch [836/1000] - Loss: 7.2350\n",
      "Epoch [837/1000] - Loss: 7.1347\n",
      "Epoch [838/1000] - Loss: 7.2384\n",
      "Epoch [839/1000] - Loss: 7.2035\n",
      "Epoch [840/1000] - Loss: 7.2636\n",
      "Epoch [841/1000] - Loss: 7.2669\n",
      "Epoch [842/1000] - Loss: 7.0748\n",
      "Epoch [843/1000] - Loss: 7.2501\n",
      "Epoch [844/1000] - Loss: 7.2086\n",
      "Epoch [845/1000] - Loss: 7.0908\n",
      "Epoch [846/1000] - Loss: 7.2044\n",
      "Epoch [847/1000] - Loss: 7.1221\n",
      "Epoch [848/1000] - Loss: 6.9437\n",
      "Epoch [849/1000] - Loss: 6.9521\n",
      "Epoch [850/1000] - Loss: 7.1680\n",
      "Epoch [851/1000] - Loss: 7.3540\n",
      "Epoch [852/1000] - Loss: 7.2523\n",
      "Epoch [853/1000] - Loss: 7.1595\n",
      "Epoch [854/1000] - Loss: 7.3083\n",
      "Epoch [855/1000] - Loss: 7.0344\n",
      "Epoch [856/1000] - Loss: 7.2348\n",
      "Epoch [857/1000] - Loss: 7.0183\n",
      "Epoch [858/1000] - Loss: 7.2628\n",
      "Epoch [859/1000] - Loss: 7.0003\n",
      "Epoch [860/1000] - Loss: 7.3086\n",
      "Epoch [861/1000] - Loss: 7.1523\n",
      "Epoch [862/1000] - Loss: 7.2614\n",
      "Epoch [863/1000] - Loss: 7.1987\n",
      "Epoch [864/1000] - Loss: 7.1631\n",
      "Epoch [865/1000] - Loss: 7.2996\n",
      "Epoch [866/1000] - Loss: 7.1811\n",
      "Epoch [867/1000] - Loss: 7.4247\n",
      "Epoch [868/1000] - Loss: 7.1117\n",
      "Epoch [869/1000] - Loss: 7.1709\n",
      "Epoch [870/1000] - Loss: 7.2179\n",
      "Epoch [871/1000] - Loss: 7.0887\n",
      "Epoch [872/1000] - Loss: 7.0599\n",
      "Epoch [873/1000] - Loss: 7.3156\n",
      "Epoch [874/1000] - Loss: 7.4194\n",
      "Epoch [875/1000] - Loss: 7.2176\n",
      "Epoch [876/1000] - Loss: 7.2373\n",
      "Epoch [877/1000] - Loss: 7.2599\n",
      "Epoch [878/1000] - Loss: 7.2556\n",
      "Epoch [879/1000] - Loss: 7.2207\n",
      "Epoch [880/1000] - Loss: 7.1628\n",
      "Epoch [881/1000] - Loss: 7.1630\n",
      "Epoch [882/1000] - Loss: 7.0126\n",
      "Epoch [883/1000] - Loss: 7.0293\n",
      "Epoch [884/1000] - Loss: 7.3593\n",
      "Epoch [885/1000] - Loss: 7.0063\n",
      "Epoch [886/1000] - Loss: 7.1712\n",
      "Epoch [887/1000] - Loss: 7.1447\n",
      "Epoch [888/1000] - Loss: 7.3155\n",
      "Epoch [889/1000] - Loss: 7.2357\n",
      "Epoch [890/1000] - Loss: 7.3233\n",
      "Epoch [891/1000] - Loss: 7.0985\n",
      "Epoch [892/1000] - Loss: 7.1361\n",
      "Epoch [893/1000] - Loss: 7.0721\n",
      "Epoch [894/1000] - Loss: 7.4315\n",
      "Epoch [895/1000] - Loss: 7.2112\n",
      "Epoch [896/1000] - Loss: 7.2949\n",
      "Epoch [897/1000] - Loss: 7.1515\n",
      "Epoch [898/1000] - Loss: 7.0617\n",
      "Epoch [899/1000] - Loss: 7.1597\n",
      "Epoch [900/1000] - Loss: 7.1648\n",
      "Epoch [901/1000] - Loss: 7.3743\n",
      "Epoch [902/1000] - Loss: 7.1038\n",
      "Epoch [903/1000] - Loss: 7.0481\n",
      "Epoch [904/1000] - Loss: 7.1798\n",
      "Epoch [905/1000] - Loss: 7.1636\n",
      "Epoch [906/1000] - Loss: 7.1875\n",
      "Epoch [907/1000] - Loss: 7.2106\n",
      "Epoch [908/1000] - Loss: 7.0524\n",
      "Epoch [909/1000] - Loss: 7.1369\n",
      "Epoch [910/1000] - Loss: 7.0817\n",
      "Epoch [911/1000] - Loss: 7.0709\n",
      "Epoch [912/1000] - Loss: 7.2065\n",
      "Epoch [913/1000] - Loss: 7.1247\n",
      "Epoch [914/1000] - Loss: 7.1865\n",
      "Epoch [915/1000] - Loss: 7.0278\n",
      "Epoch [916/1000] - Loss: 7.1803\n",
      "Epoch [917/1000] - Loss: 7.2797\n",
      "Epoch [918/1000] - Loss: 7.3096\n",
      "Epoch [919/1000] - Loss: 7.2482\n",
      "Epoch [920/1000] - Loss: 7.2605\n",
      "Epoch [921/1000] - Loss: 7.1871\n",
      "Epoch [922/1000] - Loss: 7.2358\n",
      "Epoch [923/1000] - Loss: 7.1038\n",
      "Epoch [924/1000] - Loss: 7.1306\n",
      "Epoch [925/1000] - Loss: 7.1482\n",
      "Epoch [926/1000] - Loss: 6.9886\n",
      "Epoch [927/1000] - Loss: 7.3095\n",
      "Epoch [928/1000] - Loss: 7.0420\n",
      "Epoch [929/1000] - Loss: 7.1677\n",
      "Epoch [930/1000] - Loss: 6.9825\n",
      "Epoch [931/1000] - Loss: 7.1839\n",
      "Epoch [932/1000] - Loss: 7.3227\n",
      "Epoch [933/1000] - Loss: 7.1342\n",
      "Epoch [934/1000] - Loss: 7.1565\n",
      "Epoch [935/1000] - Loss: 7.1309\n",
      "Epoch [936/1000] - Loss: 7.4277\n",
      "Epoch [937/1000] - Loss: 7.0586\n",
      "Epoch [938/1000] - Loss: 7.1363\n",
      "Epoch [939/1000] - Loss: 7.2956\n",
      "Epoch [940/1000] - Loss: 7.1719\n",
      "Epoch [941/1000] - Loss: 7.1364\n",
      "Epoch [942/1000] - Loss: 7.0206\n",
      "Epoch [943/1000] - Loss: 7.2216\n",
      "Epoch [944/1000] - Loss: 7.1445\n",
      "Epoch [945/1000] - Loss: 7.0916\n",
      "Epoch [946/1000] - Loss: 7.1378\n",
      "Epoch [947/1000] - Loss: 7.0211\n",
      "Epoch [948/1000] - Loss: 7.0939\n",
      "Epoch [949/1000] - Loss: 7.2836\n",
      "Epoch [950/1000] - Loss: 7.1021\n",
      "Epoch [951/1000] - Loss: 7.1562\n",
      "Epoch [952/1000] - Loss: 7.1372\n",
      "Epoch [953/1000] - Loss: 7.1962\n",
      "Epoch [954/1000] - Loss: 7.1412\n",
      "Epoch [955/1000] - Loss: 7.0911\n",
      "Epoch [956/1000] - Loss: 7.0187\n",
      "Epoch [957/1000] - Loss: 7.1465\n",
      "Epoch [958/1000] - Loss: 7.0768\n",
      "Epoch [959/1000] - Loss: 6.9124\n",
      "Epoch [960/1000] - Loss: 6.9191\n",
      "Epoch [961/1000] - Loss: 7.3258\n",
      "Epoch [962/1000] - Loss: 7.0584\n",
      "Epoch [963/1000] - Loss: 7.0918\n",
      "Epoch [964/1000] - Loss: 7.2847\n",
      "Epoch [965/1000] - Loss: 7.1383\n",
      "Epoch [966/1000] - Loss: 7.2779\n",
      "Epoch [967/1000] - Loss: 7.1935\n",
      "Epoch [968/1000] - Loss: 7.0518\n",
      "Epoch [969/1000] - Loss: 7.0973\n",
      "Epoch [970/1000] - Loss: 7.2019\n",
      "Epoch [971/1000] - Loss: 7.0133\n",
      "Epoch [972/1000] - Loss: 7.1116\n",
      "Epoch [973/1000] - Loss: 7.0836\n",
      "Epoch [974/1000] - Loss: 6.9566\n",
      "Epoch [975/1000] - Loss: 7.3267\n",
      "Epoch [976/1000] - Loss: 7.1079\n",
      "Epoch [977/1000] - Loss: 6.9134\n",
      "Epoch [978/1000] - Loss: 7.2249\n",
      "Epoch [979/1000] - Loss: 6.9862\n",
      "Epoch [980/1000] - Loss: 7.1265\n",
      "Epoch [981/1000] - Loss: 7.1810\n",
      "Epoch [982/1000] - Loss: 7.1475\n",
      "Epoch [983/1000] - Loss: 7.2024\n",
      "Epoch [984/1000] - Loss: 7.1728\n",
      "Epoch [985/1000] - Loss: 7.1304\n",
      "Epoch [986/1000] - Loss: 7.1897\n",
      "Epoch [987/1000] - Loss: 7.1762\n",
      "Epoch [988/1000] - Loss: 7.1006\n",
      "Epoch [989/1000] - Loss: 7.1005\n",
      "Epoch [990/1000] - Loss: 7.1074\n",
      "Epoch [991/1000] - Loss: 7.0327\n",
      "Epoch [992/1000] - Loss: 6.9472\n",
      "Epoch [993/1000] - Loss: 7.2207\n",
      "Epoch [994/1000] - Loss: 7.1530\n",
      "Epoch [995/1000] - Loss: 7.0491\n",
      "Epoch [996/1000] - Loss: 7.1474\n",
      "Epoch [997/1000] - Loss: 7.1695\n",
      "Epoch [998/1000] - Loss: 7.2205\n",
      "Epoch [999/1000] - Loss: 7.4268\n",
      "Epoch [1000/1000] - Loss: 7.2026\n",
      "Training time: 3239.11 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "loss_history = []\n",
    "\n",
    "num_batches = 100  # debug limit (increase later)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for _ in range(num_batches):\n",
    "        input_batch, label_batch = random_batch(\n",
    "            batch_size,\n",
    "            tokenized_corpus,\n",
    "            word2index,\n",
    "            window_size\n",
    "        )\n",
    "\n",
    "        input_tensor = torch.LongTensor(input_batch).unsqueeze(1)\n",
    "        label_tensor = torch.LongTensor(label_batch).unsqueeze(1)\n",
    "\n",
    "        all_vocabs = prepare_all_vocabs(vocabs, word2index, batch_size)\n",
    "\n",
    "        loss = model(input_tensor, label_tensor, all_vocabs)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot the embeddings\n",
    "\n",
    "Is fruit really near to banana?\n",
    "Is fruit really far from cat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ancestor',\n",
       " 'riverside',\n",
       " '280',\n",
       " 'holmes',\n",
       " 'prosecutor',\n",
       " 'bulky',\n",
       " 'angel',\n",
       " 'markets',\n",
       " 'accelerated',\n",
       " 'planner',\n",
       " 'diminutive',\n",
       " 'f.',\n",
       " 'combine',\n",
       " 'eighteenth',\n",
       " 'ended',\n",
       " 'head',\n",
       " 'consequently',\n",
       " 'alfred',\n",
       " 'momentum',\n",
       " 'remanding',\n",
       " 'millions',\n",
       " 'intends',\n",
       " 'governing',\n",
       " 'write',\n",
       " 'winston',\n",
       " 'stimulatory',\n",
       " 'power',\n",
       " 'drive',\n",
       " 'define',\n",
       " 'thereby',\n",
       " 'pumpkin',\n",
       " 'cocktail',\n",
       " 'exchange',\n",
       " 'stultifying',\n",
       " 'switched',\n",
       " 'replace',\n",
       " 'friend',\n",
       " \"engineers'\",\n",
       " 'wing',\n",
       " '1%',\n",
       " 'organize',\n",
       " 'herself',\n",
       " '38',\n",
       " 'shelby',\n",
       " '13',\n",
       " 'divided',\n",
       " 'lieutenant',\n",
       " 'irish',\n",
       " 'behalf',\n",
       " 'northwest',\n",
       " 'might',\n",
       " 'pullen',\n",
       " 'seconds',\n",
       " '5835',\n",
       " 'legitimate',\n",
       " 'bobby',\n",
       " 'scherer',\n",
       " 'possibility',\n",
       " 'decried',\n",
       " 'ladgham',\n",
       " 'gambling',\n",
       " 'figure',\n",
       " 'directed',\n",
       " 'switch',\n",
       " '1000',\n",
       " 'hit',\n",
       " 'unanimous',\n",
       " 'trawler',\n",
       " 'balkanizing',\n",
       " 'wrinkles',\n",
       " 'kept',\n",
       " 'roundup',\n",
       " 'generated',\n",
       " 'messrs.',\n",
       " 'ride',\n",
       " 'deadline',\n",
       " 'boothby',\n",
       " 'filly',\n",
       " 'ebbetts',\n",
       " 'jenkins',\n",
       " 'margins',\n",
       " 'plead',\n",
       " 'caucus',\n",
       " 'throneberry',\n",
       " 'paintings',\n",
       " 'minors',\n",
       " 'promptly',\n",
       " 'producers',\n",
       " 'somewhat',\n",
       " 'bexar',\n",
       " 'thinks',\n",
       " 'blackout',\n",
       " 'comus',\n",
       " 'red-prone',\n",
       " 'neighbor',\n",
       " 'washed',\n",
       " 'competitors',\n",
       " 'pan',\n",
       " 'allowing',\n",
       " 'second',\n",
       " 'reactionary',\n",
       " 'contended',\n",
       " \"underwood's\",\n",
       " '2',\n",
       " 'scotch',\n",
       " 'willy',\n",
       " 'complained',\n",
       " 'lehner',\n",
       " 'chip',\n",
       " 'listen',\n",
       " 'signed',\n",
       " 'unity',\n",
       " 'withdrawn',\n",
       " 'contain',\n",
       " 'legs',\n",
       " 'champions',\n",
       " 'weissmuller',\n",
       " 'robert',\n",
       " '$75',\n",
       " '6th',\n",
       " 'tentative',\n",
       " 'antonio',\n",
       " 'serve',\n",
       " 'seidel',\n",
       " 'peter',\n",
       " 'downstream',\n",
       " \"brocklin's\",\n",
       " '29',\n",
       " 'robbery',\n",
       " 'recipient',\n",
       " 'cold',\n",
       " 'combinations',\n",
       " 'slight',\n",
       " 'al',\n",
       " 'waveland',\n",
       " 'refurbishing',\n",
       " 'last-round',\n",
       " 'two-thirds',\n",
       " 'nurse',\n",
       " 'discredited',\n",
       " 'foreseeable',\n",
       " 'dishes',\n",
       " 'fuller',\n",
       " 'oysters',\n",
       " 'fiction',\n",
       " 'defeats',\n",
       " 'daily',\n",
       " 'robes',\n",
       " \"management's\",\n",
       " 'cites',\n",
       " 'service',\n",
       " 'meant',\n",
       " 'bowl',\n",
       " 'gallons',\n",
       " 'streamlined',\n",
       " 'shriver',\n",
       " 'bringing',\n",
       " 'developed',\n",
       " 'inheriting',\n",
       " 'cbs',\n",
       " 'thoroughly',\n",
       " 'prosecute',\n",
       " 'privileges',\n",
       " 'ross',\n",
       " '9329',\n",
       " 'hate',\n",
       " 'foreign-policy',\n",
       " 'erratic',\n",
       " 'companies',\n",
       " '280-yard',\n",
       " 'personality',\n",
       " '1960-61',\n",
       " 'precautionary',\n",
       " 'specialize',\n",
       " 'critics',\n",
       " 'restrain',\n",
       " 'dentistry',\n",
       " 'legend',\n",
       " 'gayety',\n",
       " 'poster',\n",
       " 'pocket',\n",
       " 'chicago',\n",
       " 'substitutionary',\n",
       " 'scrambled',\n",
       " 'risk',\n",
       " 'book-selection',\n",
       " 'delaney',\n",
       " 'reflected',\n",
       " 'disproportionate',\n",
       " 'corner',\n",
       " 'forsyth',\n",
       " 'greek',\n",
       " 'bahia',\n",
       " 'judson',\n",
       " 'southwestern',\n",
       " 'fernberger',\n",
       " 'goaded',\n",
       " 'straightaway',\n",
       " 'all-american',\n",
       " 'wagging',\n",
       " '11:30',\n",
       " 'instructed',\n",
       " 'anna',\n",
       " 'basically',\n",
       " 'wyman',\n",
       " 'tougas',\n",
       " 'terrace',\n",
       " 'vocals',\n",
       " 'obstacles',\n",
       " 'shouldda',\n",
       " '65,000',\n",
       " 'spontaneously',\n",
       " 'ordinarily',\n",
       " 'compensation',\n",
       " 'violated',\n",
       " 'scientific',\n",
       " 'carr',\n",
       " 'dessert',\n",
       " 'coeds',\n",
       " 'good-will',\n",
       " 'project',\n",
       " 'geeing',\n",
       " 'socola',\n",
       " 'plates',\n",
       " 'griffin',\n",
       " 'nyberg',\n",
       " 'philip',\n",
       " 'traveling',\n",
       " 'vickery',\n",
       " 'beneath',\n",
       " 'challenging',\n",
       " 'assign',\n",
       " 'starter',\n",
       " 'collided',\n",
       " 'eddy',\n",
       " '36',\n",
       " 'soft',\n",
       " 'various',\n",
       " 'coolidge',\n",
       " 'houston',\n",
       " 'immediately',\n",
       " '44',\n",
       " 'disposal',\n",
       " 'envisaged',\n",
       " 'sharpe',\n",
       " 'guarding',\n",
       " 'jolt',\n",
       " 'winner',\n",
       " \"escape's\",\n",
       " \"union's\",\n",
       " 'irwin',\n",
       " 'injury',\n",
       " 'clue',\n",
       " 'halt',\n",
       " 'mistrial',\n",
       " 'shuns',\n",
       " 'advance',\n",
       " 'nicklaus',\n",
       " ';',\n",
       " 'outclass',\n",
       " 'boiling',\n",
       " 'kicking',\n",
       " '$22.50',\n",
       " 'philharmonique',\n",
       " '3:30',\n",
       " 'let',\n",
       " 'disagreement',\n",
       " 'correct',\n",
       " 'qualities',\n",
       " 'eating',\n",
       " 'told',\n",
       " 'join',\n",
       " 'place-kicking',\n",
       " 'injection',\n",
       " 'steep',\n",
       " 'upset',\n",
       " 'reaches',\n",
       " 'written',\n",
       " 'teletype',\n",
       " 'loen',\n",
       " 'incredible',\n",
       " 'fit',\n",
       " 'angry',\n",
       " 'slash',\n",
       " 'knight',\n",
       " 'batting',\n",
       " 'commission',\n",
       " 'damages',\n",
       " 'follows',\n",
       " 'blumberg',\n",
       " \"employers'\",\n",
       " 'absorbed',\n",
       " '61st',\n",
       " 'vitally',\n",
       " 'pezza',\n",
       " 'objection',\n",
       " '225,000',\n",
       " 'forms',\n",
       " 'dampened',\n",
       " 'mink',\n",
       " 'cleaners',\n",
       " 'standing',\n",
       " 'behaving',\n",
       " 'travel',\n",
       " 'stores',\n",
       " 'taxable',\n",
       " 'stands',\n",
       " 'renaissance',\n",
       " 'catchers',\n",
       " '1927',\n",
       " '4,500',\n",
       " 'kill',\n",
       " 'grab',\n",
       " 'careers',\n",
       " 'refuted',\n",
       " 'independent',\n",
       " 'placing',\n",
       " 'arguments',\n",
       " 'halleck',\n",
       " '1311',\n",
       " 'run-up',\n",
       " 'signers',\n",
       " 'taking',\n",
       " \"jorda's\",\n",
       " 'nancy',\n",
       " 'booked',\n",
       " 'bottleneck',\n",
       " 'enunciate',\n",
       " 'rookie',\n",
       " 'woods',\n",
       " 'forming',\n",
       " 'cut',\n",
       " 'secretary-treasurer',\n",
       " 'convicted',\n",
       " 'kerr',\n",
       " 'probation',\n",
       " 'five-home',\n",
       " 'auntie',\n",
       " \"harvard's\",\n",
       " 'stand',\n",
       " 'strikingly',\n",
       " 'owens',\n",
       " 'sub-zero',\n",
       " 'culminates',\n",
       " 'suburbs',\n",
       " 'stout',\n",
       " 'manned',\n",
       " 'tahoe',\n",
       " 'parked',\n",
       " 'services',\n",
       " 'street',\n",
       " 'collections',\n",
       " 'hess',\n",
       " 'oceania',\n",
       " \"baylor's\",\n",
       " 'mood',\n",
       " 'skinner',\n",
       " 'klees',\n",
       " 'stewards',\n",
       " 'fires',\n",
       " 'simonelli',\n",
       " 'log-jam',\n",
       " 'ideological',\n",
       " '(',\n",
       " 'advisers',\n",
       " 'colonel',\n",
       " 'eva',\n",
       " 'less',\n",
       " 'recruiter',\n",
       " 'burke-rostagno',\n",
       " 'willett',\n",
       " 'licenses',\n",
       " 'shown',\n",
       " 'carriers',\n",
       " 'cotten',\n",
       " 'lady',\n",
       " 'robbing',\n",
       " 'outlays',\n",
       " 'failing',\n",
       " 'undistinguished',\n",
       " 're-arguing',\n",
       " 'stephanotis',\n",
       " 'rum',\n",
       " 'hemisphere',\n",
       " 'truce',\n",
       " 'load',\n",
       " '$200,000',\n",
       " \"glimco's\",\n",
       " 'home',\n",
       " 'aspects',\n",
       " 'shrink',\n",
       " \"palmer's\",\n",
       " 'discussing',\n",
       " 'bunkered',\n",
       " 'dating',\n",
       " 'asking',\n",
       " 'stock',\n",
       " 'lavish',\n",
       " 'rookie-of-the-year',\n",
       " 'fierce',\n",
       " 'bellboys',\n",
       " 'lloyd',\n",
       " 'sending',\n",
       " 'metal',\n",
       " 'born',\n",
       " 'eleanor',\n",
       " 'humphrey',\n",
       " 'square',\n",
       " 'included',\n",
       " \"it's\",\n",
       " 'punching',\n",
       " 'perlman',\n",
       " 'stockholders',\n",
       " 'wars',\n",
       " 'mclauchlin',\n",
       " 'stanley',\n",
       " 'capabilities',\n",
       " 'episcopal',\n",
       " 'advances',\n",
       " \"titche's\",\n",
       " 'johnston',\n",
       " 'tutors',\n",
       " 'excite',\n",
       " 'stimulant',\n",
       " 'unusual',\n",
       " 'reopening',\n",
       " 'leopold',\n",
       " 'delegate',\n",
       " 'script',\n",
       " 'mill',\n",
       " 'briskly',\n",
       " 'essence',\n",
       " 'couturier',\n",
       " 'whole',\n",
       " \"church's\",\n",
       " 'recipients',\n",
       " 'golf',\n",
       " 'rickenbaugh',\n",
       " 'train',\n",
       " 'briefs',\n",
       " 'directing',\n",
       " 'tighten',\n",
       " 'kolb',\n",
       " '68',\n",
       " 'dimaggio',\n",
       " 'quickie',\n",
       " 'dipped',\n",
       " 'agents',\n",
       " 'formby',\n",
       " 'parklike',\n",
       " '?',\n",
       " 'uniform',\n",
       " 'kestner',\n",
       " 'byer-rolnick',\n",
       " 'doubtful',\n",
       " 'workshops',\n",
       " 'part-time',\n",
       " 'williams',\n",
       " 'modern',\n",
       " 'repay',\n",
       " 'electricity',\n",
       " 'dyer',\n",
       " 'acclaim',\n",
       " 'polytechnic',\n",
       " \"green's\",\n",
       " 'recommends',\n",
       " 'geraghty',\n",
       " 'sued',\n",
       " 'applied',\n",
       " 'spahnie',\n",
       " 'whipped',\n",
       " 'strike',\n",
       " 'deterioration',\n",
       " '343',\n",
       " '65%',\n",
       " 'hung',\n",
       " 'butter',\n",
       " 'tell',\n",
       " 'clinton',\n",
       " \"one's\",\n",
       " 'aircraft',\n",
       " 'grew',\n",
       " \"arkansas'\",\n",
       " 'southern',\n",
       " 'tackle',\n",
       " \"she's\",\n",
       " 'jacqueline',\n",
       " 'favorable',\n",
       " 'wolcott',\n",
       " 'trend',\n",
       " 'trigg',\n",
       " '$50',\n",
       " 'katanga',\n",
       " \"u.'s\",\n",
       " 'courses',\n",
       " 'if',\n",
       " 'site',\n",
       " 'neuberger',\n",
       " 'possessive',\n",
       " 'fits',\n",
       " 'supporters',\n",
       " 'sapio',\n",
       " 'gordon',\n",
       " 'tourists',\n",
       " 'stirling',\n",
       " 'merry-go-round',\n",
       " 'unworkable',\n",
       " 'sustaining',\n",
       " 'one-sided',\n",
       " 'tulsa',\n",
       " 'mushrooms',\n",
       " 'scotland',\n",
       " 'captivating',\n",
       " 'attended',\n",
       " 'utterly',\n",
       " 'neutralists',\n",
       " 'cotton',\n",
       " 'shall',\n",
       " '$100',\n",
       " 'requirements',\n",
       " 'examine',\n",
       " 'urged',\n",
       " 'department',\n",
       " 'tim',\n",
       " 'fringe',\n",
       " \"today's\",\n",
       " 'clay',\n",
       " 'crowning',\n",
       " 'mali',\n",
       " 'era',\n",
       " 'objective',\n",
       " 'handicapped',\n",
       " 'allan',\n",
       " 'financial',\n",
       " '7034',\n",
       " 'tolls',\n",
       " 'conservative',\n",
       " 'softened',\n",
       " 'scarcely',\n",
       " \"drivers'\",\n",
       " '$120',\n",
       " 'questionable',\n",
       " 'prepares',\n",
       " 'disapproval',\n",
       " 'wheels',\n",
       " 'depending',\n",
       " 'rightfield',\n",
       " 'orange',\n",
       " 'sukarno',\n",
       " 'attention',\n",
       " 'buffets',\n",
       " 'calamity',\n",
       " 'mob',\n",
       " 'heinze',\n",
       " 'exaggeration',\n",
       " 'curbing',\n",
       " 'chest',\n",
       " 'beronio',\n",
       " 'instruction',\n",
       " 'matters',\n",
       " 'come',\n",
       " 'jamaican',\n",
       " 'speculating',\n",
       " 'threads',\n",
       " 'imperial',\n",
       " 'openly',\n",
       " 'erupted',\n",
       " 'durante',\n",
       " 'tri-motor',\n",
       " 'experienced',\n",
       " '1409',\n",
       " 'easily',\n",
       " 'allergic',\n",
       " 'scots',\n",
       " 'counseling',\n",
       " 'spanish',\n",
       " 'miners',\n",
       " 'broken',\n",
       " 'prominent',\n",
       " 'cedric',\n",
       " 'times-picayune',\n",
       " 'agreements',\n",
       " 'beer',\n",
       " 'sweater',\n",
       " 'basin',\n",
       " 'izvestia',\n",
       " 'reps.',\n",
       " 'ponce',\n",
       " 'generosity',\n",
       " 'dance',\n",
       " 'silhouette',\n",
       " 'poor-mouth',\n",
       " 'batted',\n",
       " 'neckline',\n",
       " 'hollander',\n",
       " 'quarter',\n",
       " 'shatilov',\n",
       " 'lawmakers',\n",
       " 'waterline',\n",
       " 'brisk',\n",
       " 'berra',\n",
       " 'paid-for',\n",
       " 'tee',\n",
       " 'carroll',\n",
       " 'lewis',\n",
       " 'fatal',\n",
       " 'survive',\n",
       " 'compared',\n",
       " 'assuming',\n",
       " 'rationale',\n",
       " 'grandfather',\n",
       " 'deposit',\n",
       " 'subjects',\n",
       " 'boehmer',\n",
       " 'gasoline',\n",
       " 'others',\n",
       " 'paneled',\n",
       " 'omsk',\n",
       " 'deficiency',\n",
       " 'costlier',\n",
       " 'interior',\n",
       " 'terminated',\n",
       " 'idealist',\n",
       " 'german',\n",
       " 'husky',\n",
       " 'skies',\n",
       " 'started',\n",
       " 'detested',\n",
       " 'shelves',\n",
       " 'behavior',\n",
       " 'waterfront',\n",
       " 'nuns',\n",
       " 'betsy',\n",
       " 'collected',\n",
       " 'gallup',\n",
       " 'clifford',\n",
       " 'indifference',\n",
       " 'collapse',\n",
       " 'volumes',\n",
       " 'retarded',\n",
       " 'us',\n",
       " 'choreography',\n",
       " 'disunity',\n",
       " 'marines',\n",
       " 'segregated',\n",
       " 'spice-nice',\n",
       " 'commercial',\n",
       " 'order',\n",
       " 'specific',\n",
       " 'edward',\n",
       " 'two-run',\n",
       " 'lobby',\n",
       " 'their',\n",
       " \"'49\",\n",
       " 'walls',\n",
       " 'colonialism',\n",
       " 'first-floor',\n",
       " 'hobart',\n",
       " 'slug',\n",
       " 'analysts',\n",
       " 'flowers',\n",
       " 'gaither',\n",
       " 'glison',\n",
       " 'couples',\n",
       " 'received',\n",
       " 'shahn',\n",
       " 're-set',\n",
       " 'clayton',\n",
       " 'fiscal',\n",
       " 'passes',\n",
       " 'republic',\n",
       " 'ill',\n",
       " 'shari',\n",
       " 'buffet',\n",
       " 'detach',\n",
       " 'relinquish',\n",
       " 'stern',\n",
       " 'reds',\n",
       " 'khrushchev',\n",
       " 'representations',\n",
       " 'railroading',\n",
       " 'federalize',\n",
       " 'identified',\n",
       " 'row',\n",
       " 'midwest',\n",
       " 'term-end',\n",
       " \"jersey's\",\n",
       " '187.5',\n",
       " 'dies',\n",
       " 'coolheaded',\n",
       " 'p.m.',\n",
       " 'suffering',\n",
       " 'bregman',\n",
       " 'fielding',\n",
       " 'ex-oriole',\n",
       " 'kickoff',\n",
       " 'ellen',\n",
       " 'author',\n",
       " 'private-eye',\n",
       " 'sub',\n",
       " 'over-the-counter',\n",
       " 'teacher-employee',\n",
       " \"wife's\",\n",
       " 'annual',\n",
       " 'those',\n",
       " 'consultation',\n",
       " 'buried',\n",
       " 'activity',\n",
       " 'leon',\n",
       " 'regional',\n",
       " 'jumpy',\n",
       " 'wyoming',\n",
       " 'realities',\n",
       " 'occasionally',\n",
       " 'locale',\n",
       " 'constitutional',\n",
       " 'thirty-eighth',\n",
       " 'tendency',\n",
       " 'women',\n",
       " 'abbey',\n",
       " 'tailback',\n",
       " 'mammoth',\n",
       " 'two-hour',\n",
       " 'intervenes',\n",
       " 'three-fifths',\n",
       " 'restriction',\n",
       " 'cambridge',\n",
       " 'jon',\n",
       " 'subs',\n",
       " 'deserves',\n",
       " 'age',\n",
       " 'sheet',\n",
       " '215',\n",
       " 'scored',\n",
       " 'french',\n",
       " 'organizers',\n",
       " 'conserve',\n",
       " 'grants',\n",
       " 'monks',\n",
       " 'penetration',\n",
       " 'supernatural',\n",
       " 'adamson',\n",
       " 'heinkel',\n",
       " \"achaeans'\",\n",
       " 'broncos',\n",
       " 'av.',\n",
       " 'floor',\n",
       " 'mothers',\n",
       " 'fully',\n",
       " 'hike',\n",
       " 'rekindling',\n",
       " 'drain',\n",
       " 'dinners',\n",
       " 'means',\n",
       " 'wards',\n",
       " 'stature',\n",
       " 'assignment',\n",
       " 'victims',\n",
       " 'buffalo',\n",
       " 'family',\n",
       " 'handsome',\n",
       " 'vented',\n",
       " 'isaac',\n",
       " 'needy',\n",
       " 'narcotic',\n",
       " 'bradley',\n",
       " 'disrepute',\n",
       " 'double',\n",
       " 'carnegie',\n",
       " 'perkins',\n",
       " 'richey',\n",
       " 'promote',\n",
       " 'listed',\n",
       " 'treat',\n",
       " 'uniquely',\n",
       " 'rates',\n",
       " 'rangy',\n",
       " 'sell',\n",
       " 'revenge',\n",
       " 'solving',\n",
       " 'challenger',\n",
       " \"'20's\",\n",
       " 'dazzler',\n",
       " 'assn.',\n",
       " 'discourage',\n",
       " 'per-game',\n",
       " 'repertory',\n",
       " 'grimly',\n",
       " 'rome',\n",
       " 'elegant',\n",
       " 'acquire',\n",
       " 'employments',\n",
       " 'mcnaughton',\n",
       " 'embroidered',\n",
       " 'murphy',\n",
       " 'irate',\n",
       " 'humor',\n",
       " 'monet',\n",
       " 'vigorously',\n",
       " 'rolled',\n",
       " 'negotiating',\n",
       " 'desire',\n",
       " 'couch',\n",
       " 'swept',\n",
       " 'thakhek',\n",
       " 'rickshaw',\n",
       " '10%',\n",
       " 'daughters',\n",
       " 'jockey',\n",
       " 'mortgage',\n",
       " 'pubs',\n",
       " 'tracks',\n",
       " 'fifth',\n",
       " 'filling',\n",
       " 'block',\n",
       " 'passport',\n",
       " 'prime',\n",
       " 'dept.',\n",
       " '1891',\n",
       " 'artists',\n",
       " 'coordinate',\n",
       " 'cited',\n",
       " 'industrialist',\n",
       " 'commissioner',\n",
       " 'hats',\n",
       " 'all',\n",
       " 'african',\n",
       " \"brooks's\",\n",
       " 'opposite',\n",
       " 'distributions',\n",
       " 'furnish',\n",
       " 'average',\n",
       " 'discrimination',\n",
       " 'dismal',\n",
       " 'hundreds',\n",
       " 'foundation',\n",
       " 'gilman',\n",
       " 'doctor',\n",
       " '8%',\n",
       " 'own',\n",
       " 'hastily',\n",
       " 'abner',\n",
       " \"fardulli's\",\n",
       " \"state's\",\n",
       " 'phil',\n",
       " 'forgetting',\n",
       " 'augusta',\n",
       " 'karol',\n",
       " 'councilwoman',\n",
       " 'lived',\n",
       " 'garza',\n",
       " 'wrongdoing',\n",
       " 'inefficient',\n",
       " 'arrow',\n",
       " 'capello',\n",
       " 'conciliatory',\n",
       " 'adjust',\n",
       " 'wage',\n",
       " 'baked',\n",
       " 'so-called',\n",
       " 'organizing',\n",
       " 'wrigley',\n",
       " 'contracts',\n",
       " 'myers',\n",
       " 'aerial',\n",
       " 'nae',\n",
       " 'patience',\n",
       " 'n.c.',\n",
       " 'heralded',\n",
       " 'hooked',\n",
       " 'blades',\n",
       " '1776',\n",
       " '1925',\n",
       " 'outset',\n",
       " '60',\n",
       " 'dividing',\n",
       " 'attraction',\n",
       " 'giveaway',\n",
       " 'welcomed',\n",
       " 'implements',\n",
       " 'smoother',\n",
       " 'turned',\n",
       " 'unmatched',\n",
       " 'expansive',\n",
       " '37,000',\n",
       " 'cerebrated',\n",
       " 'ah',\n",
       " 'arrington',\n",
       " 'although',\n",
       " 'dedication',\n",
       " 'hamilton',\n",
       " 'hardy',\n",
       " '$300,000,000',\n",
       " 'feelings',\n",
       " 'gables',\n",
       " 'salvatore',\n",
       " 'thornton',\n",
       " 'push',\n",
       " 'bridegroom',\n",
       " 'rush',\n",
       " 'wilson',\n",
       " 'wants',\n",
       " 'graduation',\n",
       " 'interference',\n",
       " 'characters',\n",
       " 'fluid',\n",
       " 'kinds',\n",
       " 'timetable',\n",
       " 'soloists',\n",
       " 'saltonstall',\n",
       " 'permitted',\n",
       " 'm.',\n",
       " 'priddy',\n",
       " 'lighters',\n",
       " 'bought',\n",
       " 'dealer',\n",
       " 'coal',\n",
       " '1-inch',\n",
       " 'bird',\n",
       " 'beatrice',\n",
       " 'kirkland',\n",
       " 'stairs',\n",
       " '``',\n",
       " 'glazer',\n",
       " 'zinc',\n",
       " '$842,617',\n",
       " 'robbed',\n",
       " '$400',\n",
       " 'company',\n",
       " 'sanctuary',\n",
       " 'mano',\n",
       " \"anderson's\",\n",
       " 'overpowered',\n",
       " 'westminster',\n",
       " 'klan',\n",
       " 'game',\n",
       " 'lehman',\n",
       " 'aparicio',\n",
       " 'instituted',\n",
       " 'hijackers',\n",
       " 'double-crosser',\n",
       " 'pulse-jet',\n",
       " 'drops',\n",
       " 'role',\n",
       " 'preserve',\n",
       " 'vivid',\n",
       " 'mutterers',\n",
       " 'sigma',\n",
       " 'keyboarding',\n",
       " 'lancashire',\n",
       " 'concluded',\n",
       " 'rite',\n",
       " '17',\n",
       " 'thanks',\n",
       " 'harvard',\n",
       " 'nevertheless',\n",
       " 'hurdle',\n",
       " 'entrant',\n",
       " 'kappa',\n",
       " 'pier',\n",
       " 'massey-ferguson',\n",
       " 'glass',\n",
       " 'emphasize',\n",
       " 'kroger',\n",
       " 'symington',\n",
       " 'bloom',\n",
       " 'intellectually',\n",
       " 'elected',\n",
       " 'barrage',\n",
       " 'spider-leg',\n",
       " 'bounds',\n",
       " 'countries',\n",
       " 'zurich',\n",
       " 'killebrew',\n",
       " 'debentures',\n",
       " 'remainder',\n",
       " 'honoring',\n",
       " 'racquet',\n",
       " 'danger',\n",
       " 'low-flying',\n",
       " 'origin',\n",
       " 'spectators',\n",
       " 'recalled',\n",
       " 'painted',\n",
       " 'chain',\n",
       " '$15,000',\n",
       " 'leo',\n",
       " 'tiny',\n",
       " 'cardinals',\n",
       " 'bread',\n",
       " 'ever-present',\n",
       " 'edges',\n",
       " 'vigor',\n",
       " 'deliver',\n",
       " 'frictions',\n",
       " 'underwriters',\n",
       " 'place',\n",
       " 'earnings',\n",
       " 'mohammedanism',\n",
       " 'winning',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4431])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacancy  = torch.LongTensor([word2index['vacancy']])\n",
    "vacancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3932,  1.9187, -1.4765,  0.2749, -0.3883,  1.3673, -0.2101,  0.2205,\n",
       "          0.8679,  0.4388, -0.4976, -1.6523,  0.2384, -0.6107,  0.2607, -0.3961]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacancy_embed_c = model.embedding_center(vacancy)\n",
    "vacancy_embed_o = model.embedding_outside(vacancy)\n",
    "vacancy_embed   = (vacancy_embed_c + vacancy_embed_o) / 2\n",
    "vacancy_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9660,  2.3769, -2.6512,  0.8991, -1.5455,  2.9225, -1.5926,  0.5084,\n",
       "          1.5604, -0.2556, -1.2418, -2.0451,  1.8463, -1.6750,  2.2145, -0.0404]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacancy_embed_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(word):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index['<UNK>']\n",
    "        \n",
    "    word = torch.LongTensor([word2index[word]])\n",
    "    \n",
    "    embed_c = model.embedding_center(word)\n",
    "    embed_o = model.embedding_outside(word)\n",
    "    embed   = (embed_c + embed_o) / 2\n",
    "    \n",
    "    return embed[0][0].item(), embed[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.3932214379310608, 1.9187487363815308)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('vacancy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.04833585023880005, 0.5312590599060059)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('death')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.4162105917930603, 0.5549201369285583)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.32414400577545166, 0.7908587455749512)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('offense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words_to_plot = [\n",
    "    'vacancy', 'death', 'jobs',\n",
    "    'offense', 'architecture',\n",
    "    '<UNK>'\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "for word in words_to_plot:\n",
    "    x, y = get_embed(word)\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, (x, y), xytext=(5, 2), textcoords='offset points')\n",
    "\n",
    "plt.title(\"Word Embeddings (2D Skip-gram)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.04833585023880005, 0.5312590599060059)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('death')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.4162105917930603, 0.5549201369285583)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('jobs')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.32414400577545166, 0.7908587455749512)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('offense')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.3932214379310608, 1.9187487363815308)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('vacancy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15633037686347961, 0.07511040568351746)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.9204288721084595, 0.6153717041015625)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('archives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words_to_plot = [\n",
    "    'vacancy', 'death', 'jobs',\n",
    "    'offense', 'architecture',\n",
    "    '<UNK>'\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "for word in words_to_plot:\n",
    "    x, y = get_embed(word)\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, (x, y), xytext=(5, 2), textcoords='offset points')\n",
    "\n",
    "plt.title(\"Word Embeddings (2D Skip-gram)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing an entire vocabulary in 2D often results in a dense, indistinguishable cluster because the high-dimensional complexity of the embeddings is being forced into a very limited space. To facilitate a clearer analysis of semantic relationships, a smaller, relevant subset of words was plotted instead. This visualization reveals that \"jobs\" is positioned significantly closer to \"vacancy\" than to \"death,\" which serves as evidence that the Skip-gram model effectively learned and encoded semantic similarities during training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.4162105917930603, 0.5549201369285583)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = get_embed('jobs')\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.3932214379310608, 1.9187487363815308)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacancy = get_embed('vacancy')\n",
    "vacancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.6345962882041931, 1.482042670249939)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk = get_embed('<UNK>')\n",
    "unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9715858462628756\n",
      "0.9041599347782353\n"
     ]
    }
   ],
   "source": [
    "#more formally is to divide by its norm\n",
    "def cosine_similarity(A, B):\n",
    "    dot_product = np.dot(A, B)\n",
    "    norm_a = np.linalg.norm(A)\n",
    "    norm_b = np.linalg.norm(B)\n",
    "    similarity = dot_product / (norm_a * norm_b)\n",
    "    return similarity\n",
    "\n",
    "print(cosine_similarity(np.array(jobs), np.array(unk)))\n",
    "print(cosine_similarity(np.array(jobs), np.array(vacancy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8510623963876026\n",
      "0.9041599347782353\n"
     ]
    }
   ],
   "source": [
    "death = get_embed('death')\n",
    "\n",
    "print(cosine_similarity(np.array(jobs), np.array(death)))\n",
    "print(cosine_similarity(np.array(jobs), np.array(vacancy)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "# Step 1: build final embedding matrix\n",
    "W = (model.embedding_center.weight.detach().cpu().numpy() +\n",
    "     model.embedding_outside.weight.detach().cpu().numpy()) / 2\n",
    "\n",
    "# Normalize embeddings for fast cosine similarity\n",
    "W_norm = W / np.linalg.norm(W, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "\n",
    "def get_vector(word):\n",
    "    if word not in word2index:\n",
    "        return None\n",
    "    return W_norm[word2index[word]] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13113, 16)\n",
      "[-0.20106998  0.26808012 -0.05495613  0.23297642  0.04949834  0.43485382\n",
      " -0.25304687 -0.42731324  0.36987573  0.08645177 -0.21185087  0.20732209\n",
      "  0.17741612 -0.22580732  0.19722441  0.19677474]\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(W.shape)\n",
    "print(get_vector(\"jobs\"))\n",
    "print(len(get_vector(\"jobs\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = {idx: word for word, idx in word2index.items()}\n",
    "def predict_analogy(a, b, c, W_norm, word2index, index2word):\n",
    "    if a not in word2index or b not in word2index or c not in word2index:\n",
    "        return None\n",
    "\n",
    "    va = W_norm[word2index[a]]\n",
    "    vb = W_norm[word2index[b]]\n",
    "    vc = W_norm[word2index[c]]\n",
    "\n",
    "    # Vector arithmetic: b - a + c\n",
    "    target = vb - va + vc\n",
    "    target = target / np.linalg.norm(target)\n",
    "\n",
    "    # Cosine similarity with ALL words at once\n",
    "    similarities = np.dot(W_norm, target)\n",
    "\n",
    "    # Exclude input words\n",
    "    for w in (a, b, c):\n",
    "        similarities[word2index[w]] = -1\n",
    "\n",
    "    best_index = np.argmax(similarities)\n",
    "    return index2word[best_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'workable'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_analogy(\"jobs\", \"vacancy\", \"death\", W, word2index, index2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_analogies(file_path, W_norm, word2index, index2word):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            words = line.strip().split()\n",
    "            if len(words) != 4:\n",
    "                continue\n",
    "\n",
    "            a, b, c, d = words\n",
    "            prediction = predict_analogy(\n",
    "                a, b, c, W_norm, word2index, index2word\n",
    "            )\n",
    "\n",
    "            if prediction is None:\n",
    "                continue\n",
    "\n",
    "            total += 1\n",
    "            if prediction == d:\n",
    "                correct += 1\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy, correct, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_acc, sem_correct, sem_total = evaluate_analogies(\n",
    "    \"country-capital.txt\",\n",
    "    W,\n",
    "    word2index,\n",
    "    index2word\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic accuracy (capital-common-countries): 0.0000 (0/0)\n",
      "Syntactic accuracy (past-tense): 0.0000 (0/648)\n"
     ]
    }
   ],
   "source": [
    "syntactic_acc, syn_correct, syn_total = evaluate_analogies(\n",
    "    \"past-tense.txt\",\n",
    "    W,\n",
    "    word2index,\n",
    "    index2word\n",
    ")\n",
    "\n",
    "print(f\"Semantic accuracy (capital-common-countries): {semantic_acc:.4f} ({sem_correct}/{sem_total})\")\n",
    "print(f\"Syntactic accuracy (past-tense): {syntactic_acc:.4f} ({syn_correct}/{syn_total})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Human (mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>sex</td>\n",
       "      <td>6.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiger</td>\n",
       "      <td>cat</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book</td>\n",
       "      <td>paper</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>7.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word 1    Word 2  Human (mean)\n",
       "0      love       sex          6.77\n",
       "1     tiger       cat          7.35\n",
       "2     tiger     tiger         10.00\n",
       "3      book     paper          7.46\n",
       "4  computer  keyboard          7.62"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "similarity_df = pd.read_csv(\"combined.csv\")\n",
    "similarity_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used pairs: 197\n",
      "Skipped OOV pairs: 156\n"
     ]
    }
   ],
   "source": [
    "model_scores = []\n",
    "human_scores = []\n",
    "skipped = 0\n",
    "\n",
    "for _, row in similarity_df.iterrows():\n",
    "    w1 = row[\"Word 1\"]\n",
    "    w2 = row[\"Word 2\"]\n",
    "    human_score = row[\"Human (mean)\"]\n",
    "\n",
    "    if w1 not in word2index or w2 not in word2index:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    v1 = W_norm[word2index[w1]]\n",
    "    v2 = W_norm[word2index[w2]]\n",
    "\n",
    "    model_sim = np.dot(v1, v2)  # cosine similarity\n",
    "\n",
    "    model_scores.append(model_sim)\n",
    "    human_scores.append(human_score)\n",
    "\n",
    "print(f\"Used pairs: {len(model_scores)}\")\n",
    "print(f\"Skipped OOV pairs: {skipped}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation: -0.0844\n",
      "P-value: 2.3832e-01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "correlation, p_value = spearmanr(model_scores, human_scores)\n",
    "\n",
    "print(f\"Spearman correlation: {correlation:.4f}\")\n",
    "print(f\"P-value: {p_value:.4e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example comparisons:\n",
      "love sex Human: 6.77 Model: 0.696\n",
      "tiger cat Human: 7.46 Model: 0.677\n",
      "tiger tiger Human: 5.77 Model: 0.459\n",
      "book paper Human: 6.31 Model: 0.368\n",
      "computer keyboard Human: 7.5 Model: 0.711\n"
     ]
    }
   ],
   "source": [
    "print(\"Example comparisons:\")\n",
    "for i in range(5):\n",
    "    print(\n",
    "        similarity_df.iloc[i, 0],\n",
    "        similarity_df.iloc[i, 1],\n",
    "        \"Human:\", human_scores[i],\n",
    "        \"Model:\", round(model_scores[i], 3)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary and Visualization Analysis**\n",
    "\n",
    "In this notebook, we implemented a **Word2Vec (Skip-gram)** model to learn word embeddings from a subset of the Reuters corpus. The following key observations were made during the evaluation phase:\n",
    "\n",
    "* **Dimensionality Challenges:** When plotting the entire vocabulary in a 2D space, the embeddings appear as a dense, indistinguishable cluster. This is primarily due to the significant reduction in dimensionality (compressing high-dimensional vectors into 2D) and the large volume of words being visualized simultaneously.\n",
    "* **Semantic Proximity:** To better analyze the model's performance, a specific subset of relevant words was isolated. The resulting visualization clearly shows that **\"jobs\"** is positioned much closer to **\"vacancy\"** than it is to **\"death.\"**\n",
    "* **Model Validation:** This geometric proximity indicates that the Skip-gram model successfully captured semantic similarities from the training data, effectively grouping words that share similar contexts in the vector space.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
